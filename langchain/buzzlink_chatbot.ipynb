{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "487d8d79-5ee9-4aa4-9fdf-cd5f4303e099",
      "metadata": {
        "id": "487d8d79-5ee9-4aa4-9fdf-cd5f4303e099"
      },
      "source": [
        "## Setup\n",
        "\n",
        "### Components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9154da88",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard library imports\n",
        "import json\n",
        "import os\n",
        "import getpass\n",
        "from IPython.display import Image, display\n",
        "from datetime import datetime\n",
        "\n",
        "# LangChain imports\n",
        "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
        "from langchain.docstore.document import Document\n",
        "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
        "from langchain_qdrant import QdrantVectorStore\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Qdrant imports\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.models import Distance, VectorParams, models\n",
        "\n",
        "# LangGraph imports\n",
        "from langgraph.graph import MessagesState, StateGraph, END\n",
        "from langgraph.prebuilt import ToolNode, tools_condition"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "156e5192",
      "metadata": {},
      "source": [
        "LangChain API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2c9c36f7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# LangChain API key: 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\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b667376e",
      "metadata": {},
      "source": [
        "Generative Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fab0dd56-7437-4aeb-af20-7f420d47ca94",
      "metadata": {
        "id": "fab0dd56-7437-4aeb-af20-7f420d47ca94"
      },
      "outputs": [],
      "source": [
        "# Local model\n",
        "# llm = ChatOllama(model=\"llama3.1:latest\")\n",
        "\n",
        "# OpenAI model, requires API key\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\", temperature=0)\n",
        "# Ensure the response is in JSON format\n",
        "llm = llm.bind(response_format={\"type\": \"json_object\"}) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da14773e-ac98-4a97-944b-4c6ec028d195",
      "metadata": {
        "id": "da14773e-ac98-4a97-944b-4c6ec028d195"
      },
      "source": [
        "Embedding Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4691bd31-d8f4-4ba1-aec5-44935400f33c",
      "metadata": {
        "id": "4691bd31-d8f4-4ba1-aec5-44935400f33c"
      },
      "outputs": [],
      "source": [
        "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22fdc314-b91d-4820-b0a8-873b5b6e76f5",
      "metadata": {
        "id": "22fdc314-b91d-4820-b0a8-873b5b6e76f5"
      },
      "source": [
        "Vector Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "137d3848-7265-4673-9779-4c5f604da469",
      "metadata": {
        "id": "137d3848-7265-4673-9779-4c5f604da469"
      },
      "outputs": [],
      "source": [
        "REUSE_COLLECTION = True\n",
        "\n",
        "qdrant_client = QdrantClient(\n",
        "    url = \"https://6dfee087-1d0f-4a2c-97e3-d9dae27836bf.us-east-1-0.aws.cloud.qdrant.io\",\n",
        "    api_key= \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.I4HaiEeiATI7j2vYoYkKTFszON1OLs-ekegJqxmx-cw\"\n",
        ") \n",
        "\n",
        "collection_name = \"user_profile_collection_with_ollama\"\n",
        "\n",
        "collections = qdrant_client.get_collections()\n",
        "if collection_name not in [collection.name for collection in collections.collections]:\n",
        "    qdrant_client.create_collection(\n",
        "        collection_name=collection_name,\n",
        "        vectors_config=VectorParams(\n",
        "            size=768, \n",
        "            distance=Distance.COSINE \n",
        "        )\n",
        "    )\n",
        "    print(f\"Collection '{collection_name}' created successfully!\")\n",
        "\n",
        "vector_store = QdrantVectorStore(\n",
        "    client=qdrant_client,\n",
        "    collection_name=collection_name,\n",
        "    embedding=embeddings\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa6ba684-26cf-4860-904e-a4d51380c134",
      "metadata": {
        "id": "fa6ba684-26cf-4860-904e-a4d51380c134"
      },
      "source": [
        "## Steps\n",
        "### Indexing\n",
        "Load JSON data and preprocess it into a list of documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a2ec5e5e",
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_PATH = \"../data/raw-profile-data/profile_data.json\"\n",
        "\n",
        "def _get_with_condition(dictionary, key, condition_values=[None, \"\"], default=\"Unknown\"):\n",
        "    value = dictionary.get(key, default)\n",
        "    return default if value in condition_values else value\n",
        "\n",
        "def preprocess_alumni_profile(data_path):\n",
        "    \"\"\"\n",
        "    Create one document for each alumnus JSON profile, and return a list of documents.\n",
        "    These documents are then stored in a vector store for later retrieval.\n",
        "    These documents contain a summary of the alumnus's work experiences and education history with their names, LinkedIn URLs and profile pictures as metadata.\n",
        "    \"\"\"\n",
        "    with open(data_path, 'r') as f:\n",
        "        alumni_profiles = json.load(f)\n",
        "        documents = []\n",
        "        for alumnus in alumni_profiles:\n",
        "            companies = set()\n",
        "            id, name, about, headline, location, profile_pic, experiences, educations = _get_with_condition(alumnus, 'id'), _get_with_condition(alumnus, \"name\"), _get_with_condition(alumnus, \"about\"), _get_with_condition(alumnus,\"headline\"), _get_with_condition(alumnus,\"location\"), _get_with_condition(alumnus,\"profile_pic\"), _get_with_condition(alumnus,\"experiences\"), _get_with_condition(alumnus,\"educations\")\n",
        "            intro_line = f\"{name} is a {headline} at {location}. {name} self-describes as {about}.\"\n",
        "            exp_lines, edu_lines = [f\"{name}'s work experiences are as follows:\"], [f\"{name}'s education history is as follows:\"]\n",
        "            for idx, exp in enumerate(experiences):\n",
        "                title, company, work_type, location, start, end, description = _get_with_condition(exp, \"title\"), _get_with_condition(exp, \"company\"), _get_with_condition(exp, \"work_type\"), _get_with_condition(exp, \"location\"), _get_with_condition(exp, \"start_date\"), _get_with_condition(exp, \"end_date\"), _get_with_condition(exp, \"description\")\n",
        "                exp_lines.append(f\"{idx+1}. Role: {title}\\nCompany: {company}\\nWork Type: {work_type}\\nLocation: {location}\\nDuration: {start} to {end}\\nDescription: {description}\")\n",
        "                companies.add(company)\n",
        "            for idx, edu in enumerate(educations):\n",
        "                school, degree, major, start, end, description = _get_with_condition(edu, \"school\"), _get_with_condition(edu, \"degree\"), _get_with_condition(edu, \"major\"), _get_with_condition(edu, \"start_date\"), _get_with_condition(edu, \"end_date\"), _get_with_condition(edu, \"description\")\n",
        "                edu_lines.append(f\"{idx+1}. School: {school}\\nDegree: {degree}\\nMajor: {major}\\nDuration: {start} to {end}\\nDescription: {description}\")\n",
        "\n",
        "            alumnus_profile_summary = f\"{intro_line}\\n\\n\" + \"\\n\".join(exp_lines) + \"\\n\\n\" + \"\\n\".join(edu_lines)\n",
        "            doc = Document(page_content=alumnus_profile_summary, metadata={\"id\": id, \"name\": name, \"profile_pic\": profile_pic, \"companies\": list(companies)})\n",
        "            documents.append(doc)\n",
        "        return documents\n",
        "    \n",
        "def preprocess_alumni_profile_with_manual_split(data_path):\n",
        "    \"\"\"\n",
        "    Create one or more documents for each alumnus JSON profile based on the split, and return a list of documents.\n",
        "    These documents are then stored in a vector store for later retrieval.\n",
        "    These documents contain a summary of the alumnus's work experiences and education history with their names, LinkedIn URLs and profile pictures as metadata.\n",
        "    Each profile should have the following splits:\n",
        "    \n",
        "    summary: {page_content: <headline+location+bio>, metadata:{id, pic, name, location, role, company, work_type, work_duration, school, degree, major, school_duration}}\n",
        "    each work exp: {page_content: <title+company+work_type+start_date+end_date+location+description>, metadata:{id, pic, name, location, role, company, work_type, work_duration, school, degree, major, school_duration}}\n",
        "    each edu hist: {page_content: <school+degree+major+start_date+end_date+description>, metadata:{id, pic, name, role, location, company, work_type, work_duration, school, degree, major, school_duration}}\n",
        "    \"\"\"\n",
        "    with open(data_path, 'r') as f:\n",
        "        alumni_profiles = json.load(f)\n",
        "        documents = []\n",
        "        for alumnus in alumni_profiles:\n",
        "            # summary\n",
        "            id, name, about, headline, location, profile_pic, experiences, educations = _get_with_condition(alumnus, 'id'), _get_with_condition(alumnus, \"name\"), _get_with_condition(alumnus, \"about\"), _get_with_condition(alumnus,\"headline\"), _get_with_condition(alumnus,\"location\"), _get_with_condition(alumnus,\"profile_pic\"), _get_with_condition(alumnus,\"experiences\"), _get_with_condition(alumnus,\"educations\")\n",
        "            summary_line = f\"{name} is a {headline} at {location}. {name} self-describes as {about}\"\n",
        "            summary_doc = Document(page_content=summary_line, metadata={\"id\":id, \"name\":name, \"profile_pic\":profile_pic, \"location\":location, \"role\":None, \"company\":None, \"work_type\":None, \"work_duration\":None, \"school\":None, \"degree\":None, \"major\":None, \"school_duration\":None})\n",
        "\n",
        "            # work exps\n",
        "            work_docs = []\n",
        "            for exp in experiences:\n",
        "                title, company, work_type, work_location, start, end, description = _get_with_condition(exp, \"title\"), _get_with_condition(exp, \"company\"), _get_with_condition(exp, \"work_type\"), _get_with_condition(exp, \"location\"), _get_with_condition(exp, \"start_date\"), _get_with_condition(exp, \"end_date\"), _get_with_condition(exp, \"description\")\n",
        "                exp_line = f\"Name: {name}\\nRole: {title}\\nCompany: {company}\\nWork Type: {work_type}\\nLocation: {work_location}\\nDuration: {start} to {end}\\nDescription: {description}\"\n",
        "                work_docs.append(Document(page_content=exp_line, metadata={\"id\":id, \"name\":name, \"profile_pic\":profile_pic, \"location\":work_location, \"role\":title, \"company\":company, \"work_type\":work_type, \"work_duration\":f\"{start} to {end}\", \"school\":None, \"degree\":None, \"major\":None, \"school_duration\":None}))\n",
        "\n",
        "            # edu hist\n",
        "            edu_docs = []                \n",
        "            for edu in educations:\n",
        "                school, degree, major, start, end, description = _get_with_condition(edu, \"school\"), _get_with_condition(edu, \"degree\"), _get_with_condition(edu, \"major\"), _get_with_condition(edu, \"start_date\"), _get_with_condition(edu, \"end_date\"), _get_with_condition(edu, \"description\")\n",
        "                edu_line = f\"School: {school}\\nDegree: {degree}\\nMajor: {major}\\nDuration: {start} to {end}\\nDescription: {description}\"\n",
        "                edu_docs.append(Document(page_content=edu_line, metadata={\"id\":id, \"name\":name, \"profile_pic\":profile_pic, \"location\":None, \"role\":None, \"company\":None, \"work_type\":None, \"work_duration\":None, \"school\":school, \"degree\":degree, \"major\":major, \"school_duration\":f\"{start} to {end}\"}))\n",
        "\n",
        "            documents.extend([summary_doc] + work_docs + edu_docs)\n",
        "        return documents\n",
        "\n",
        "# def preprocess_alumni_profile_with_llm_split(data_path):\n",
        "#     \"\"\"\n",
        "#     Create one or more documents for each alumnus JSON profile based on the split with a LLM, and return a list of documents.\n",
        "#     These documents are then stored in a vector store for later retrieval.\n",
        "#     These documents contain a summary of the alumnus's work experiences and education history with their names, LinkedIn URLs and profile pictures as metadata.\n",
        "#     Each profile should have the following splits:\n",
        "#     {page_content: summary, metadata:{id, pic, name, role, company, work_type, work_location, work_duration, school, degree, major, school_duration, skills}}\n",
        "#     \"\"\"\n",
        "#     with open(data_path, 'r') as f:        \n",
        "#         human_prompt_temp = \"\"\"\n",
        "#                 You will be given one CONTEXT, containing information about a person, role, or education. \n",
        "#                 For **each** item:\n",
        "\n",
        "#                 1. Produce a concise summary (2–5 sentences) to highlight experiences and skills.\n",
        "#                 2. Extract the following fields if they exist:\n",
        "#                 - name            \n",
        "#                 - role\n",
        "#                 - company\n",
        "#                 - work_type\n",
        "#                 - work_location\n",
        "#                 - work_duration\n",
        "#                 - school\n",
        "#                 - degree\n",
        "#                 - major\n",
        "#                 - school_duration\n",
        "#                 - skills\n",
        "\n",
        "#                 3. Return the results as valid JSON object. \n",
        "#                 - If a field does not exist in the text, return null as value.\n",
        "#                 - Do **not** wrap your JSON in markdown/code fences.\n",
        "#                 - No additional text outside the JSON.\n",
        "#                 - For the “skills” field, you may either attempt to infer them from context (e.g., “game development,” “AWS,” “cloud computing,” etc.) or return a [] as value it if not clearly indicated.\n",
        "#                 - For the \"work_duration\" and \"school_duration\" fields, the value must be in the format of \"Month Year to Month Year\" (e.g. \"May 2024 to January 2025\"). Note that values like \"Present\" and \"Unknown\" are ALLOWED.\n",
        "\n",
        "#                 CONTEXT:\n",
        "#                 {context}\n",
        "\n",
        "#                 ---\n",
        "#                 **Example Output Format**:\n",
        "\n",
        "#                 {{\n",
        "#                     \"summary\": \"Short summary goes here...\",\n",
        "#                     \"name\": \"...\",\n",
        "#                     \"role\": \"...\",\n",
        "#                     \"company\": \"...\",\n",
        "#                     \"work_type\": \"...\",\n",
        "#                     \"work_location\": \"...\",\n",
        "#                     \"work_duration\": \"...\",\n",
        "#                     \"school\": \"...\",\n",
        "#                     \"degree\": \"...\",\n",
        "#                     \"major\": \"...\",\n",
        "#                     \"school_duration\": \"...\",\n",
        "#                     \"skills\": [\"...\", \"...\"]                \n",
        "#                 }}           \n",
        "#                 Make sure to follow these instructions carefully. Return **only** this JSON object.\n",
        "#                 \"\"\"\n",
        "#         system_prompt_temp = \"\"\"\n",
        "#                 You are a helpful assistant who extracts and summarizes information into a JSON object.              \n",
        "#                 \"\"\"\n",
        "#         human_prompt = HumanMessagePromptTemplate.from_template(human_prompt_temp)\n",
        "#         system_prompt = SystemMessage(system_prompt_temp)\n",
        "#         prompt = ChatPromptTemplate.from_messages([            \n",
        "#             system_prompt,\n",
        "#             human_prompt,\n",
        "#         ])\n",
        "#         # llm = ChatOllama(model=\"llama3.1:latest\", temperature=0, format=\"json\")\n",
        "#         llm = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\", temperature=0)\n",
        "#         llm = llm.bind(response_format={\"type\": \"json_object\"})\n",
        "#         chain = prompt | llm\n",
        "\n",
        "#         alumni_profiles = json.load(f)\n",
        "#         documents = []\n",
        "#         count = 0\n",
        "#         for alumnus in alumni_profiles:\n",
        "#             # summary\n",
        "#             id, name, about, headline, location, profile_pic, experiences, educations = _get_with_condition(alumnus, 'id'), _get_with_condition(alumnus, \"name\"), _get_with_condition(alumnus, \"about\"), _get_with_condition(alumnus,\"headline\"), _get_with_condition(alumnus,\"location\"), _get_with_condition(alumnus,\"profile_pic\"), _get_with_condition(alumnus,\"experiences\"), _get_with_condition(alumnus,\"educations\")\n",
        "            \n",
        "#             summary_line = f\"{name} is a {headline} at {location}. {name} self-describes as {about}\"\n",
        "#             summary_res = chain.invoke({\"context\": summary_line})\n",
        "#             summary_res = json.loads(summary_res.content)\n",
        "#             summary_res.update({\"id\": id, \"name\": name, \"profile_pic\": profile_pic})\n",
        "#             documents.append(summary_res)\n",
        "#             count += 1\n",
        "#             if count >= 2: break\n",
        "#             # work exps            \n",
        "#             for exp in experiences:\n",
        "#                 title, company, work_type, location, start, end, description = _get_with_condition(exp, \"title\"), _get_with_condition(exp, \"company\"), _get_with_condition(exp, \"work_type\"), _get_with_condition(exp, \"location\"), _get_with_condition(exp, \"start_date\"), _get_with_condition(exp, \"end_date\"), _get_with_condition(exp, \"description\")\n",
        "#                 exp_line = f\"Name: {name}\\nRole: {title}\\nCompany: {company}\\nWork Type: {work_type}\\nLocation: {location}\\nDuration: {start} to {end}\\nDescription: {description}\"\n",
        "#                 exp_res = chain.invoke({\"context\": exp_line})\n",
        "#                 exp_res = json.loads(exp_res.content)\n",
        "#                 exp_res.update({\"id\": id, \"name\": name, \"profile_pic\": profile_pic})\n",
        "#                 documents.append(exp_res)\n",
        "#                 count += 1\n",
        "#                 if count >= 2: break\n",
        "#             # edu hist                         \n",
        "#             for edu in educations:\n",
        "#                 school, degree, major, start, end, description = _get_with_condition(edu, \"school\"), _get_with_condition(edu, \"degree\"), _get_with_condition(edu, \"major\"), _get_with_condition(edu, \"start_date\"), _get_with_condition(edu, \"end_date\"), _get_with_condition(edu, \"description\")\n",
        "#                 edu_line = f\"Name:{name}\\nSchool: {school}\\nDegree: {degree}\\nMajor: {major}\\nDuration: {start} to {end}\\nDescription: {description}\"\n",
        "#                 edu_res = chain.invoke({\"context\": edu_line})\n",
        "#                 edu_res = json.loads(edu_res.content)\n",
        "#                 edu_res.update({\"id\": id, \"name\": name, \"profile_pic\": profile_pic})\n",
        "#                 documents.append(edu_res)\n",
        "#                 count += 1\n",
        "#                 if count >= 2: break\n",
        "#         return documents\n",
        "\n",
        "# def store_preprocessed_docs(docs, vector_store):\n",
        "#     new_docs = []\n",
        "#     for doc in docs:\n",
        "#                 new_docs.append(\n",
        "#                     Document(\n",
        "#                     page_content=doc[\"summary\"],\n",
        "#                     metadata={\n",
        "#                         \"id\": doc[\"id\"],\n",
        "#                         \"name\": doc[\"name\"],\n",
        "#                         \"profile_pic\": doc[\"profile_pic\"],\n",
        "#                         \"role\": doc[\"role\"],\n",
        "#                         \"company\": doc[\"company\"],\n",
        "#                         \"work_type\": doc[\"work_type\"],\n",
        "#                         \"work_location\": doc[\"work_location\"],\n",
        "#                         \"work_duration\": doc[\"work_duration\"],\n",
        "#                         \"school\": doc[\"school\"],\n",
        "#                         \"degree\": doc[\"degree\"],\n",
        "#                         \"major\": doc[\"major\"],\n",
        "#                         \"school_duration\": doc[\"school_duration\"],\n",
        "#                         \"skills\": doc[\"skills\"]\n",
        "#                     }\n",
        "#                 )\n",
        "#             )\n",
        "#     vector_store.add_documents(documents=new_docs)\n",
        "\n",
        "if not REUSE_COLLECTION:\n",
        "    docs = preprocess_alumni_profile_with_manual_split(DATA_PATH)\n",
        "    print(docs[0])\n",
        "    print(docs[1])\n",
        "    vector_store.add_documents(documents=docs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42c26d5f-1493-4ad6-9210-ea2723695149",
      "metadata": {
        "id": "42c26d5f-1493-4ad6-9210-ea2723695149"
      },
      "source": [
        "### Retrival and Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29b2e525",
      "metadata": {},
      "source": [
        "Make a graph to chain our model operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e27d97f0-27dc-438b-bf61-a403ca284522",
      "metadata": {
        "id": "e27d97f0-27dc-438b-bf61-a403ca284522"
      },
      "outputs": [],
      "source": [
        "graph_builder = StateGraph(MessagesState)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35eeb6a1-29f2-4086-8b6f-8761cf24ce59",
      "metadata": {
        "id": "35eeb6a1-29f2-4086-8b6f-8761cf24ce59"
      },
      "source": [
        "Define functions for tool calling, which helps the model to preprocess user raw input and decide whether need to run the retrival step or not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8201a6ef-942f-4571-b3b9-55a430590266",
      "metadata": {
        "id": "8201a6ef-942f-4571-b3b9-55a430590266"
      },
      "outputs": [],
      "source": [
        "def extract_search_parameters(query: str):\n",
        "    \"\"\"Use LLM to extract search parameters from a user query.\"\"\"\n",
        "    \n",
        "    system_message = \"\"\"\n",
        "    You are an intelligent assistant that extracts useful parameters from user queries into a JSON object.\n",
        "    Your task is to identify any people names, companies, titles, locations, and duration time mentioned in the user query, and return a JSON object with the extracted information.\n",
        "    You MUST return an empty array [] as values if you can not find any information for the parameters.\n",
        "    \n",
        "    Return your response in the following format:\n",
        "    {{names: [...], companies: [...], titles: [...], locations: [...], duration: [...], skills: [...]}}\n",
        "\n",
        "    For the duration parameter, if it is present tense, add 'Present' to the parameter.\n",
        "    <start_date to end_date> pair should ONLY take one entry in the duration parameter.\n",
        "    You MUST also expand any short forms of months into the full month name.\n",
        "    \n",
        "    Example:\n",
        "    Query: \"Who works at Google as a Data Analyst with AWS experience?\"\n",
        "    Response:\n",
        "    {{names: [], companies: [\"Google\"], titles: [\"Data Analyst\"], locations: [], duration: [], skills: [\"AWS\"]}}\n",
        "    \n",
        "    Query: \"Yihao Mai's experience at IBM\"\n",
        "    Response:\n",
        "    {{names: [\"Yihao Mai\"], companies: [\"IBM\"], titles: [], locations: [], duration: [], skills: []}}\n",
        "    \n",
        "    Query: \"Who worked at Amazon as a Software Engineer intern in May 2025\"\n",
        "    Response:\n",
        "    {{names: [], companies: [\"Amazon\"], titles: [\"Software Engineer\"], locations: [], duration: [\"May 2025\"]}}\n",
        "    \"\"\"\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", system_message),\n",
        "        (\"human\", \"Extract search parameters from the following query: {query}\")\n",
        "    ])\n",
        "    \n",
        "    response = llm.invoke(prompt.format_messages(query=query))\n",
        "    \n",
        "    content = json.loads(response.content)\n",
        "    print(f\"Parsed search parameters: {content}\")\n",
        "    return content\n",
        "\n",
        "\n",
        "\n",
        "@tool(response_format=\"content_and_artifact\")\n",
        "def retrieve(query: str):\n",
        "    \"\"\"Retrieve information related to a query.\"\"\"\n",
        "    \n",
        "    # Extract parameters from the query\n",
        "    params = extract_search_parameters(query)\n",
        "    # companies = params.get(\"companies\", [])\n",
        "    # names = params.get(\"names\", [])\n",
        "    \n",
        "    # print(f\"Search parameters: companies={companies}, names={names}\")\n",
        "    \n",
        "    # # Create filters based on extracted parameters\n",
        "    # filter_conditions = None\n",
        "    # should_conditions = []\n",
        "    \n",
        "    # if companies:\n",
        "    #     should_conditions.append(\n",
        "    #         models.FieldCondition(\n",
        "    #             key=\"metadata.companies\",\n",
        "    #             match=models.MatchAny(any=companies)\n",
        "    #         )\n",
        "    #     )\n",
        "    \n",
        "    # # Process names for improved matching with firstname+lastinitial format\n",
        "    # if names:\n",
        "    #     for full_name in names:\n",
        "    #         # Split the name into parts\n",
        "    #         name_parts = full_name.split()\n",
        "            \n",
        "    #         if len(name_parts) >= 1:\n",
        "    #             # First name matching is critical - this will match with firstname+lastinitial\n",
        "    #             first_name = name_parts[0]\n",
        "    #             should_conditions.append(\n",
        "    #                 models.FieldCondition(\n",
        "    #                     key=\"metadata.name\",\n",
        "    #                     match=models.MatchText(text=first_name)\n",
        "    #                 )\n",
        "    #             )\n",
        "                \n",
        "    #             # If we have a last name, create a condition for first name + first letter of last name\n",
        "    #             if len(name_parts) >= 2:\n",
        "    #                 last_name = name_parts[-1]\n",
        "    #                 last_name_initial = last_name[0] if last_name else \"\"\n",
        "                    \n",
        "    #                 # Create pattern like \"John S\" for \"John Smith\"\n",
        "    #                 first_plus_last_initial = f\"{first_name} {last_name_initial}\"\n",
        "    #                 should_conditions.append(\n",
        "    #                     models.FieldCondition(\n",
        "    #                         key=\"metadata.name\",\n",
        "    #                         match=models.MatchText(text=first_plus_last_initial)\n",
        "    #                     )\n",
        "    #                 )\n",
        "                    \n",
        "    #                 # Also try just the first letter initial with a period \"John S.\"\n",
        "    #                 first_plus_last_initial_period = f\"{first_name} {last_name_initial}.\"\n",
        "    #                 should_conditions.append(\n",
        "    #                     models.FieldCondition(\n",
        "    #                         key=\"metadata.name\",\n",
        "    #                         match=models.MatchText(text=first_plus_last_initial_period)\n",
        "    #                     )\n",
        "    #                 )\n",
        "                \n",
        "    #             # Also try the full name match for completeness\n",
        "    #             should_conditions.append(\n",
        "    #                 models.FieldCondition(\n",
        "    #                     key=\"metadata.name\",\n",
        "    #                     match=models.MatchText(text=full_name)\n",
        "    #                 )\n",
        "    #             )\n",
        "    \n",
        "    # # Only create filter if we have conditions\n",
        "    # if should_conditions:\n",
        "    #     filter_conditions = models.Filter(should=should_conditions)\n",
        "    \n",
        "    # # For \"who is\" type queries, boost with content matching too\n",
        "    # content_filter = None\n",
        "    # if names and (\"who is\" in query.lower() or \"tell me about\" in query.lower()):\n",
        "    #     # Create a content matching condition to find the name in profile text\n",
        "    #     content_conditions = []\n",
        "    #     for name in names:\n",
        "    #         content_conditions.append(\n",
        "    #             models.FieldCondition(\n",
        "    #                 key=\"page_content\",\n",
        "    #                 match=models.MatchText(text=name)\n",
        "    #             )\n",
        "    #         )\n",
        "    #     if content_conditions:\n",
        "    #         content_filter = models.Filter(should=content_conditions)\n",
        "    \n",
        "    # # Default retrieved documents\n",
        "    # retrieved_docs = []\n",
        "    \n",
        "    # # Get documents based on metadata filters\n",
        "    # if filter_conditions:\n",
        "    #     metadata_docs = vector_store.similarity_search(query, k=15, filter=filter_conditions)\n",
        "    #     retrieved_docs.extend(metadata_docs)\n",
        "    \n",
        "    # # If we have content filter and need more results, try that as well\n",
        "    # if content_filter and len(retrieved_docs) < 3:\n",
        "    #     content_docs = vector_store.similarity_search(query, k=15, filter=content_filter)\n",
        "        \n",
        "    #     # Add any new documents (not already in retrieved_docs)\n",
        "    #     existing_ids = [doc.metadata['id'] for doc in retrieved_docs]\n",
        "    #     for doc in content_docs:\n",
        "    #         if doc.metadata['id'] not in existing_ids:\n",
        "    #             retrieved_docs.append(doc)\n",
        "    #             existing_ids.append(doc.metadata['id'])\n",
        "    \n",
        "    # # If we still don't have enough results, try pure similarity search\n",
        "    # if len(retrieved_docs) < 2 and names:\n",
        "    #     # For name searches, try a more direct approach with just the name\n",
        "    #     for name in names:\n",
        "    #         similarity_docs = vector_store.similarity_search(name, k=15)\n",
        "            \n",
        "    #         # Add any new documents\n",
        "    #         existing_ids = [doc.metadata['id'] for doc in retrieved_docs]\n",
        "    #         for doc in similarity_docs:\n",
        "    #             if doc.metadata['id'] not in existing_ids:\n",
        "    #                 retrieved_docs.append(doc)\n",
        "    #                 existing_ids.append(doc.metadata['id'])\n",
        "    \n",
        "    # # If no results from filters or not using filters, fall back to similarity search\n",
        "    # if not retrieved_docs:\n",
        "    #     retrieved_docs = vector_store.similarity_search(query, k=15)\n",
        "    \n",
        "    retrieved_docs = vector_store.similarity_search(query, k=15)\n",
        "\n",
        "    serialized = []\n",
        "    for idx, doc in enumerate(retrieved_docs):\n",
        "        page_content, metadata = doc.page_content, doc.metadata\n",
        "        id, name, pic, location, role, company, work_type, work_duration, school, degree, major, school_duration = metadata['id'], metadata['name'], metadata['profile_pic'], metadata['location'], metadata['role'], metadata['company'], metadata['work_type'], metadata['work_duration'], metadata['school'], metadata['degree'], metadata['major'], metadata['school_duration']    \n",
        "        content = f\"{idx+1}. Content: {page_content}\\nId: {id}\\nName: {name}\\nProfile Pic: {pic}\"\n",
        "        serialized.append(content)\n",
        "        serialized.append(\"\\n\\n\")\n",
        "    \n",
        "    serialized = \"\".join(serialized)\n",
        "    \n",
        "    if not retrieved_docs:\n",
        "        return \"No matching alumni profiles found.\", []\n",
        "    \n",
        "    return serialized, retrieved_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b03f752-d46d-4070-b790-197b742c4dc2",
      "metadata": {
        "id": "9b03f752-d46d-4070-b790-197b742c4dc2"
      },
      "source": [
        "Define step functions for the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "4d0ce8c9-b404-424b-886e-c1386368ec24",
      "metadata": {
        "id": "4d0ce8c9-b404-424b-886e-c1386368ec24"
      },
      "outputs": [],
      "source": [
        "CURR_MONTH_YEAR = datetime.now().strftime(\"%B %Y\")\n",
        "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
        "def query_or_respond(state: MessagesState):\n",
        "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
        "\n",
        "    # Rewrite the user query into one of the following canonical forms based on its intended temporal context.\n",
        "    system_message = SystemMessage(\n",
        "    \"You are a specialized assistant for Georgia Tech students seeking information about GT alumni. \"\n",
        "    \"Your task is to transform the user query into a canonical question or statement about a person’s experience, \"\n",
        "    \"including any combination of the following elements, preserving the user’s intended tense (past, present, or future):\"\n",
        "    \"\\n\\n- Name: <name>\"\n",
        "    \"\\n- Position Title: <position_title>\"\n",
        "    \"\\n- Company: <company>\"\n",
        "    \"\\n- Location: <location>\"\n",
        "    \"\\n- Skills: <skills>\"\n",
        "    \"\\n- Time Period: <time_period> (e.g. 'from Jan 2018 to Dec 2020,' 'from January 2020 to Present,' 'in May 2023,' etc.)\"\n",
        "    \"\\n\\nIf the user mentions words like 'previously,' treat it as past tense (worked). \"\n",
        "    \"If they mention 'currently,' 'now', 'present', treat it as present tense (presently works). \"\n",
        "    \"If they mention 'will' or 'plans to,' treat it as future tense (will work).\"\n",
        "    \"\\n\\nChoose from the following canonical forms. Use only those placeholders the user actually provides; omit any placeholders they do not mention. \"\n",
        "    \"Combine them as needed to reflect the user’s request:\"\n",
        "    \"\\n\\n1) Who worked / presently works / will work as <position_title>?\"\n",
        "    \"\\n2) Who worked / presently works / will work at <company>?\"\n",
        "    \"\\n3) Who worked / presently works / will work in <location>?\"\n",
        "    \"\\n4) Who worked / presently works / will work with <skills>?\"\n",
        "    \"\\n5) Who worked / presently works / will work as <position_title> with <skills>?\"\n",
        "    \"\\n6) Who worked / presently works / will work at <company> with <skills>?\"\n",
        "    \"\\n7) Who worked / presently works / will work in <location> with <skills>?\"\n",
        "    \"\\n8) Who worked / presently works / will work as <position_title> at <company>?\"\n",
        "    \"\\n9) Who worked / presently works / will work as <position_title> in <location>?\"\n",
        "    \"\\n10) Who worked / presently works / will work at <company> in <location>?\"\n",
        "    \"\\n11) Who worked / presently works / will work as <position_title> at <company> in <location>?\"\n",
        "    \"\\n12) Who worked / presently works / will work as <position_title> at <company> with <skills>?\"\n",
        "    \"\\n13) Who worked / presently works / will work as <position_title> in <location> with <skills>?\"\n",
        "    \"\\n14) Who worked / presently works / will work at <company> in <location> with <skills>?\"\n",
        "    \"\\n\\n15) Who worked / presently works / will work as <position_title> during <time_period>?\"\n",
        "    \"\\n16) Who worked / presently works / will work at <company> during <time_period>?\"\n",
        "    \"\\n17) Who worked / presently works / will work in <location> during <time_period>?\"\n",
        "    \"\\n18) Who worked / presently works / will work with <skills> during <time_period>?\"\n",
        "    \"\\n19) Who worked / presently works / will work as <position_title> at <company> during <time_period>?\"\n",
        "    \"\\n20) Who worked / presently works / will work as <position_title> in <location> during <time_period>?\"\n",
        "    \"\\n21) Who worked / presently works / will work at <company> in <location> during <time_period>?\"\n",
        "    \"\\n22) Who worked / presently works / will work with <skills> at <company> in <location> during <time_period>?\"\n",
        "    \"\\n23) Who worked / presently works / will work as <position_title> with <skills> during <time_period>?\"\n",
        "    \"\\n24) Who worked / presently works / will work as <position_title> at <company> with <skills> during <time_period>?\"\n",
        "    \"\\n25) Who worked / presently works / will work as <position_title> in <location> with <skills> during <time_period>?\"\n",
        "    \"\\n26) Who worked / presently works / will work as <position_title> at <company> in <location> with <skills> during <time_period>?\"\n",
        "    \"\\n\\n27) <name>'s experience as a <position_title>?\"\n",
        "    \"\\n28) <name>'s experience as a <position_title> at <company>?\"\n",
        "    \"\\n29) <name>'s experience as a <position_title> in <location>?\"\n",
        "    \"\\n30) <name>'s experience at <company> in <location>?\"\n",
        "    \"\\n31) <name>'s experience with <skills>?\"\n",
        "    \"\\n32) <name>'s experience as a <position_title> with <skills>?\"\n",
        "    \"\\n33) <name>'s experience at <company> with <skills>?\"\n",
        "    \"\\n34) <name>'s experience in <location> with <skills>?\"\n",
        "    \"\\n\\n35) <name>'s experience as a <position_title> at <company> in <location> with <skills>?\"\n",
        "    \"\\n36) <name>'s experience as a <position_title> during <time_period>?\"\n",
        "    \"\\n37) <name>'s experience at <company> during <time_period>?\"\n",
        "    \"\\n38) <name>'s experience in <location> during <time_period>?\"\n",
        "    \"\\n39) <name>'s experience with <skills> during <time_period>?\"\n",
        "    \"\\n40) <name>'s experience as a <position_title> at <company> in <location> with <skills> during <time_period>?\"\n",
        "    \"\\n\\nAs soon as you successfully match the user’s query to one of these forms, rewrite it in that form and then use the retrieve tool to find alumni information. \"\n",
        "    \"If the user's query already meet one of these forms, you STILL need to use the retrieve tool to find alumni information.\"\n",
        "    \"Otherwise, do not rewrite it and do not call the retrieve tool.\"\n",
        ")\n",
        "\n",
        "    messages = [system_message] + state[\"messages\"]\n",
        "    llm_with_tools = llm.bind_tools([retrieve]) # Only tells the model there's an available tool to use. The model will decide whether to use it depending on the input message\n",
        "    response = llm_with_tools.invoke(messages)\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "\n",
        "# Step 2: Execute the retrieval.\n",
        "tools = ToolNode([retrieve])\n",
        "\n",
        "\n",
        "# Step 3: Generate a response using the retrieved content.\n",
        "def generate(state: MessagesState):\n",
        "    \"\"\"Generate answer.\"\"\"\n",
        "    # Get generated ToolMessages\n",
        "    recent_tool_messages = []\n",
        "    for message in reversed(state[\"messages\"]):\n",
        "        if message.type == \"tool\":\n",
        "            recent_tool_messages.append(message)\n",
        "        else:\n",
        "            break\n",
        "    tool_messages = recent_tool_messages[::-1]\n",
        "\n",
        "    # Format into prompt\n",
        "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
        "    \n",
        "\n",
        "    conversation_messages = [\n",
        "        message\n",
        "        for message in state[\"messages\"]\n",
        "        if message.type in (\"human\", \"system\")\n",
        "        or (message.type == \"ai\" and not message.tool_calls)\n",
        "    ]\n",
        "    \n",
        "    # Create a static system message for instructing behavior.\n",
        "    system_message = SystemMessage(\n",
        "        \"You are an assistant for helping Georgia Tech college students find information about Georgia Tech alumni. \"\n",
        "        \"You are given a question and a list of retrieved documents about Georgia Tech alumni. \"\n",
        "        \"ONLY use the facts from the provided DOCUMENT to answer the question. \"\n",
        "        \"Do not incorporate any external or pre-existing knowledge. \"\n",
        "        \"If the DOCUMENT does not contain sufficient information to answer the question, return [].\"\n",
        "    )\n",
        "    \n",
        "    human_message_content = f\"\"\"\n",
        "        INSTRUCTIONS:\n",
        "        • Answer the QUESTION using ONLY the facts provided in the DOCUMENT.\n",
        "        • Do not include any information not present in the DOCUMENT.\n",
        "        • You MUST scan through the entire DOCUMENT list and use all documents that can be helpful to answer the QUESTION.\n",
        "        • If the DOCUMENT does not contain the facts needed to answer the question, return an empty list [].\n",
        "        • You MUST return your answer in a list of JSON objects, and each object contains: \n",
        "            1. name: the alumnus's name, \n",
        "            2. id: the alumnus's id, \n",
        "            3. pic: the alumnus's profile picture URL\n",
        "            4. summary: summary of alumnus experience using the information from the DOCUMENT.\n",
        "        • Treat any duration whose end date is the literal word “Present”/\"Unknown\" as ongoing on TODAY.\n",
        "        • If a question asks about current / present / now, USE ONLY documents whose end‑date == “Present” or \"Unknown\".\n",
        "        • If a question asks “as of <year>” or “after <month year>”, include only docs active on that date:\n",
        "            A document {{start, end}} is active on DATE if start ≤ DATE ≤ end (or end == “Present” or \"Unknown\").\n",
        "        \n",
        "        DOCUMENT:\n",
        "        {docs_content}\n",
        "\n",
        "        QUESTION:\n",
        "        {conversation_messages[-1].content}\n",
        "        \"\"\"\n",
        "\n",
        "    human_message = HumanMessage(human_message_content)\n",
        "\n",
        "    prompt = [system_message, human_message]\n",
        " \n",
        "    # Run\n",
        "    response = llm.invoke(prompt)\n",
        "\n",
        "    \n",
        "    # print(\"=== DEBUG PROMPT ===\")\n",
        "    # for msg in prompt:\n",
        "    #     print(f\"Type: {msg.type}\")\n",
        "    #     print(f\"Content: {msg.content}\")\n",
        "    #     print(\"---\")\n",
        "\n",
        "    # print(\"=== DEBUG RESPONSE ===\")\n",
        "    # print(f\"Type: {response.type}\")\n",
        "    # print(f\"Content: {response.content}\")\n",
        "    # print(\"===================\")\n",
        "\n",
        "\n",
        "    return {\"messages\": [response]}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b409ee5f-2973-47ee-a1bf-112731843c5d",
      "metadata": {
        "id": "b409ee5f-2973-47ee-a1bf-112731843c5d"
      },
      "source": [
        "Finally, we compile our application into a single `graph` object. In this case, we are just connecting the steps into a sequence. We also allow the first `query_or_respond` step to \"short-circuit\" and respond directly to the user if it does not generate a tool call. This allows our application to support conversational experiences-- e.g., responding to generic greetings that may not require a retrieval step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ac33f19c-7959-4526-8f12-0de76ae10387",
      "metadata": {
        "id": "ac33f19c-7959-4526-8f12-0de76ae10387"
      },
      "outputs": [],
      "source": [
        "graph_builder.add_node(query_or_respond)\n",
        "graph_builder.add_node(tools)\n",
        "graph_builder.add_node(generate)\n",
        "\n",
        "graph_builder.set_entry_point(\"query_or_respond\")\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"query_or_respond\",\n",
        "    tools_condition,\n",
        "    {END: END, \"tools\": \"tools\"},\n",
        ")\n",
        "graph_builder.add_edge(\"tools\", \"generate\")\n",
        "graph_builder.add_edge(\"generate\", END)\n",
        "\n",
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "5c7e1717-d262-4947-a64d-6b116e53856a",
      "metadata": {
        "id": "5c7e1717-d262-4947-a64d-6b116e53856a",
        "outputId": "62e0053c-9e37-4815-ac2e-cc0dfc125f67"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "236b6209-ee06-42ba-b266-d90d9cbf224b",
      "metadata": {
        "id": "236b6209-ee06-42ba-b266-d90d9cbf224b"
      },
      "source": [
        "## Testing\n",
        "\n",
        "Note that it responds appropriately to messages that do not require an additional retrieval step:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "4fbca953-970d-4271-be30-6c7799893dd1",
      "metadata": {
        "id": "4fbca953-970d-4271-be30-6c7799893dd1",
        "outputId": "31d6fe54-5084-428b-c380-b3609df9b126"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Hello. I'm Yihao. How are you?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hello Yihao! I'm here to assist you with any information you need about Georgia Tech alumni. How can I help you today?\n"
          ]
        }
      ],
      "source": [
        "input_message = \"Hello. I'm Yihao. How are you?\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5df5046d-4610-4ffa-9f30-d04453da05a9",
      "metadata": {
        "id": "5df5046d-4610-4ffa-9f30-d04453da05a9"
      },
      "source": [
        "And when executing a search, we can stream the steps to observe the query generation, retrieval, and answer generation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "9ab78984-d7fa-40e1-a440-c041a6456c1f",
      "metadata": {
        "id": "9ab78984-d7fa-40e1-a440-c041a6456c1f",
        "outputId": "da0f5594-22c7-4aa1-fb0a-c2e998dea95b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Who works at Amazon from May 2024 to Aug 2024 with skills in AWS\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (call_9fzJdpZi0Xrh2N8MmgYcUTsy)\n",
            " Call ID: call_9fzJdpZi0Xrh2N8MmgYcUTsy\n",
            "  Args:\n",
            "    query: Who will work at Amazon during May 2024 to Aug 2024 with skills in AWS?\n",
            "Parsed search parameters: {'names': [], 'companies': ['Amazon'], 'titles': [], 'locations': [], 'duration': ['May 2024 to August 2024'], 'skills': ['AWS']}\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "1. Content: Name: William Tjokroamidjojo\n",
            "Role: Software Development Engineer Intern\n",
            "Company: Amazon\n",
            "Work Type: Unknown\n",
            "Location: Austin, Texas, United States\n",
            "Duration: May 2024 to Aug 2024\n",
            "Description: Skills: Amazon Web Services (AWS)\n",
            "Id: https://www.linkedin.com/in/william-tjokroamidjojo/\n",
            "Name: William Tjokroamidjojo\n",
            "Profile Pic: https://media.licdn.com/dms/image/v2/D4E03AQEIh5fVaT_-lA/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1690842342466?e=1749081600&v=beta&t=4vMBsI_TdxH56ua6eUESn3GomYw3hxlxM2ysN4kxo48\n",
            "\n",
            "2. Content: Name: Abhiram Bharatham\n",
            "Role: Software Engineer\n",
            "Company: Amazon\n",
            "Work Type: Full-time\n",
            "Location: Seattle, Washington, United States\n",
            "Duration: Aug 2024 to Present\n",
            "Description: Working at Amazon API - caching layer and data plane for amazon.com.\n",
            "Id: https://www.linkedin.com/in/abhiram-bharatham-8059a5179/\n",
            "Name: Abhiram Bharatham\n",
            "Profile Pic: https://media.licdn.com/dms/image/v2/C4D03AQEbEiKPV-s6NQ/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1631917448231?e=1749081600&v=beta&t=7csh8eKVRcU3uw3fpFVU8R6CnV3RN4njT1WiKmIOaxI\n",
            "\n",
            "3. Content: Name: Rayan Dabbagh\n",
            "Role: Software Engineer, AWS AI/ML\n",
            "Company: Amazon Web Services (AWS)\n",
            "Work Type: Unknown\n",
            "Location: Seattle, Washington, United States · Hybrid\n",
            "Duration: May 2022 to Aug 2022\n",
            "Description: Amazon Comprehend 📊\n",
            "\n",
            "• Developed a ticket classification alg. with an accuracy rate of 85% using Python. This system was built upon a robust natural-language processing (NLP) algorithm that analyzes factors such as ticket descriptions, message content, titles, and other pertinent features.\n",
            "Id: https://www.linkedin.com/in/rayandabbagh/\n",
            "Name: Rayan Dabbagh\n",
            "Profile Pic: https://media.licdn.com/dms/image/v2/D4E03AQFQGYnNnBX89A/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1700854119564?e=1749081600&v=beta&t=v-QRUjEPpbbvpU0TmWXKd6iYaFfEImexjM7Pi0XG9-s\n",
            "\n",
            "4. Content: Name: Harsha Gaddipati\n",
            "Role: Software Engineer Intern\n",
            "Company: Amazon Web Services (AWS)\n",
            "Work Type: Internship\n",
            "Location: Seattle, Washington, United States · Hybrid\n",
            "Duration: May 2024 to Aug 2024\n",
            "Description: Working on AWS Certificate Manager team\n",
            "Id: https://www.linkedin.com/in/harsha-gaddipati-032bb820a/\n",
            "Name: Harsha Gaddipati\n",
            "Profile Pic: https://media.licdn.com/dms/image/v2/D5603AQE2SYK8Ie-O2Q/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1718240806248?e=1749081600&v=beta&t=2T875WmiP3w2Ke8cg7G4Wl_Yr4MzZNvtHTl7BsUs_WE\n",
            "\n",
            "5. Content: Name: Rayan Dabbagh\n",
            "Role: Full-Stack Software Engineer, AWS Storage\n",
            "Company: Amazon Web Services (AWS)\n",
            "Work Type: Full-time\n",
            "Location: New York City Metropolitan Area · On-site\n",
            "Duration: May 2023 to Unknown\n",
            "Description: • AWS Elastic File System (EFS)\n",
            "\n",
            "Building features and maintaining systems at the world’s leading cloud-based file system provider, delivering ultra-scalable, high-performance storage solutions for top enterprises across all industries.\n",
            "\n",
            "Youngest full-time hire in AWS File Storage at 20 (~1k employees).\n",
            "Id: https://www.linkedin.com/in/rayandabbagh/\n",
            "Name: Rayan Dabbagh\n",
            "Profile Pic: https://media.licdn.com/dms/image/v2/D4E03AQFQGYnNnBX89A/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1700854119564?e=1749081600&v=beta&t=v-QRUjEPpbbvpU0TmWXKd6iYaFfEImexjM7Pi0XG9-s\n",
            "\n",
            "6. Content: Name: Saarang Prabhuram\n",
            "Role: Software Engineer\n",
            "Company: Amazon Web Services (AWS)\n",
            "Work Type: Full-time\n",
            "Location: Seattle, Washington, United States\n",
            "Duration: Oct 2024 to Present\n",
            "Description: Unknown\n",
            "Id: https://www.linkedin.com/in/saarang-p/\n",
            "Name: Saarang Prabhuram\n",
            "Profile Pic: https://media.licdn.com/dms/image/v2/D5603AQEwtVWHFTVrfg/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1695888203849?e=1749081600&v=beta&t=NYl5QKqdcpwh0guvEZl4aYwPn9Fsncv5mgYztH6Aghs\n",
            "\n",
            "7. Content: Name: Benjamin Stracner\n",
            "Role: Software Engineer Intern\n",
            "Company: Amazon Web Services (AWS)\n",
            "Work Type: Internship\n",
            "Location: Seattle, Washington, United States · On-site\n",
            "Duration: May 2024 to Aug 2024\n",
            "Description: • Built an AWS Fargate web service that enables AWS customers to connect Amazon Bedrock GenAI chatbots with end users via SMS.\n",
            "• Allows multiple users to concurrently communicate with different chatbots.\n",
            "• Leveraged multiple languages- Java, Smithy and TypeScript- and build systems- Gradle and Amazon internal tools.\n",
            "Id: https://www.linkedin.com/in/benjamin-stracner-5417981b8/\n",
            "Name: Benjamin Stracner\n",
            "Profile Pic: https://media.licdn.com/dms/image/v2/D5603AQHfmiiJ4R798g/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1694628758866?e=1749081600&v=beta&t=tM5_nb6xn7Crt3iMX-RHAfKTetUAnJd25yipuKL6vvk\n",
            "\n",
            "8. Content: Name: Jeffrey Z.\n",
            "Role: Software Engineer\n",
            "Company: Amazon Web Services (AWS)\n",
            "Work Type: Unknown\n",
            "Location: Unknown\n",
            "Duration: May 2024 to Aug 2024\n",
            "Description: Software Engineer Intern at AWS's AVP (Amazon Verified Permissions) team. Developed and benchmarked new API endpoint for the team service.\n",
            "Id: https://www.linkedin.com/in/jeffreyzhang2002/\n",
            "Name: Jeffrey Z.\n",
            "Profile Pic: https://media.licdn.com/dms/image/v2/C4D03AQFjcX2qqZM5QA/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1633894423371?e=1749081600&v=beta&t=xZBdNA21eGMkIPrOXAQR5SQDb8mtd_VdcyV_hF0fy5Y\n",
            "\n",
            "9. Content: Name: Aneesh Seemakurthy\n",
            "Role: Software Development Engineer Intern\n",
            "Company: Amazon Web Services (AWS)\n",
            "Work Type: Internship\n",
            "Location: New York City Metropolitan Area\n",
            "Duration: May 2024 to Aug 2024\n",
            "Description: Amazon Elastic Container Service (ECS)\n",
            "Id: https://www.linkedin.com/in/aneesh-seemakurthy/\n",
            "Name: Aneesh Seemakurthy\n",
            "Profile Pic: https://media.licdn.com/dms/image/v2/D4E03AQGmSG5ID9ZDOw/profile-displayphoto-shrink_800_800/B4EZXuF4fLHUAc-/0/1743456274662?e=1749081600&v=beta&t=tLeFQORxEsG9DyHhktcCTj9XsNSD1dtiMKshSAZahQU\n",
            "\n",
            "10. Content: Name: Arnav Patidar\n",
            "Role: Software Development Engineer Intern\n",
            "Company: Amazon\n",
            "Work Type: Internship\n",
            "Location: New York, New York, United States\n",
            "Duration: May 2024 to Aug 2024\n",
            "Description: Ads - Publisher Technology\n",
            "\n",
            "Skills:Java · Python (Programming Language) · Elasticsearch · API Development · QueryDSL · Software Development Life Cycle (SDLC)\n",
            "Id: https://www.linkedin.com/in/arnavpatidar\n",
            "Name: Arnav Patidar\n",
            "Profile Pic: https://media.licdn.com/dms/image/v2/D4E03AQG0gY6hPjZEjg/profile-displayphoto-shrink_200_200/profile-displayphoto-shrink_200_200/0/1668463395069?e=1747872000&v=beta&t=2-vwzRO8gbZAZ5NEtKpXO6-vH9FJ_wvXikU2boYH9BY\n",
            "\n",
            "11. Content: Name: Emily Liu\n",
            "Role: Software Development Intern\n",
            "Company: Amazon Web Services (AWS)\n",
            "Work Type: Internship\n",
            "Location: Unknown\n",
            "Duration: May 2024 to Aug 2024\n",
            "Description: AWS Launch Wizard\n",
            "Id: https://www.linkedin.com/in/emilyliu9/\n",
            "Name: Emily Liu\n",
            "Profile Pic: https://media.licdn.com/dms/image/v2/D5603AQFabemXZCe9ig/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1689139490004?e=1749081600&v=beta&t=0NKPmfwoSqAWhc5sRSpe2gdx4xwSUN_2UA7rSjUSPBk\n",
            "\n",
            "12. Content: Name: Sagar Gupta\n",
            "Role: Software Engineer Intern\n",
            "Company: Amazon\n",
            "Work Type: Internship\n",
            "Location: Arlington, Virginia, United States\n",
            "Duration: Jun 2024 to Aug 2024\n",
            "Description: AWS Identity and Access Management (IAM)\n",
            "Id: https://www.linkedin.com/in/sagar-gupta22/\n",
            "Name: Sagar Gupta\n",
            "Profile Pic: https://media.licdn.com/dms/image/v2/D5603AQFl5NwPg1z33g/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1686024588837?e=1749081600&v=beta&t=n6s11xfV1NJcZUfs7P1fhS24aOVyiZGf3jJlzF1e1HE\n",
            "\n",
            "13. Content: Name: Asmita Karandikar\n",
            "Role: Software Development Engineer Intern\n",
            "Company: Amazon Web Services (AWS)\n",
            "Work Type: Internship\n",
            "Location: Seattle, Washington, United States · On-site\n",
            "Duration: May 2024 to Aug 2024\n",
            "Description: Unknown\n",
            "Id: https://www.linkedin.com/in/asmitakar/\n",
            "Name: Asmita Karandikar\n",
            "Profile Pic: https://media.licdn.com/dms/image/v2/D5603AQHqy4k-owFihQ/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1706672777404?e=1749081600&v=beta&t=52kAdQN3mdfkq6Hec9PTHq-e26lwqPvgsejsn0VrfIA\n",
            "\n",
            "14. Content: Name: Pramod Chunduri\n",
            "Role: Applied Scientist Intern\n",
            "Company: Amazon Web Services (AWS)\n",
            "Work Type: Internship\n",
            "Location: San Francisco Bay Area · On-site\n",
            "Duration: May 2024 to Present\n",
            "Description: Skills: Large Language Models (LLM) · Artificial Intelligence (AI) · Natural Language Processing (NLP) · Information Retrieval\n",
            "Id: https://www.linkedin.com/in/pramod-chunduri/\n",
            "Name: Pramod Chunduri\n",
            "Profile Pic: https://media.licdn.com/dms/image/v2/C4D03AQEzQFJVuNaxFw/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1618506670099?e=1749081600&v=beta&t=Q15FwWaz5CMb9dNbMYEOk5sT5SFh0BNX6pV2X_tL84U\n",
            "\n",
            "15. Content: Name: Patrick Guo\n",
            "Role: Incoming Software Development Engineer\n",
            "Company: Amazon Web Services (AWS)\n",
            "Work Type: Full-time\n",
            "Location: Seattle, Washington, United States\n",
            "Duration: Oct 2024 to Unknown\n",
            "Description: Unknown\n",
            "Id: https://www.linkedin.com/in/patrickguo123/\n",
            "Name: Patrick Guo\n",
            "Profile Pic: https://media.licdn.com/dms/image/v2/D4E03AQFTNb2IE0yK2A/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1714799312426?e=1749081600&v=beta&t=86hDhI6PtYVCeqsSyLkWgHDxTC4G0-HEJtB-cfKXJpE\n",
            "\n",
            "\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "{\n",
            "  \"result\": [\n",
            "    {\n",
            "      \"name\": \"William Tjokroamidjojo\",\n",
            "      \"id\": \"https://www.linkedin.com/in/william-tjokroamidjojo/\",\n",
            "      \"pic\": \"https://media.licdn.com/dms/image/v2/D4E03AQEIh5fVaT_-lA/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1690842342466?e=1749081600&v=beta&t=4vMBsI_TdxH56ua6eUESn3GomYw3hxlxM2ysN4kxo48\",\n",
            "      \"summary\": \"Software Development Engineer Intern at Amazon, working from May 2024 to Aug 2024. Skills include Amazon Web Services (AWS).\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Harsha Gaddipati\",\n",
            "      \"id\": \"https://www.linkedin.com/in/harsha-gaddipati-032bb820a/\",\n",
            "      \"pic\": \"https://media.licdn.com/dms/image/v2/D5603AQE2SYK8Ie-O2Q/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1718240806248?e=1749081600&v=beta&t=2T875WmiP3w2Ke8cg7G4Wl_Yr4MzZNvtHTl7BsUs_WE\",\n",
            "      \"summary\": \"Software Engineer Intern at Amazon Web Services (AWS), working from May 2024 to Aug 2024 on the AWS Certificate Manager team.\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Benjamin Stracner\",\n",
            "      \"id\": \"https://www.linkedin.com/in/benjamin-stracner-5417981b8/\",\n",
            "      \"pic\": \"https://media.licdn.com/dms/image/v2/D5603AQHfmiiJ4R798g/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1694628758866?e=1749081600&v=beta&t=tM5_nb6xn7Crt3iMX-RHAfKTetUAnJd25yipuKL6vvk\",\n",
            "      \"summary\": \"Software Engineer Intern at Amazon Web Services (AWS), working from May 2024 to Aug 2024. Built an AWS Fargate web service for connecting Amazon Bedrock GenAI chatbots with end users.\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Emily Liu\",\n",
            "      \"id\": \"https://www.linkedin.com/in/emilyliu9/\",\n",
            "      \"pic\": \"https://media.licdn.com/dms/image/v2/D5603AQFabemXZCe9ig/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1689139490004?e=1749081600&v=beta&t=0NKPmfwoSqAWhc5sRSpe2gdx4xwSUN_2UA7rSjUSPBk\",\n",
            "      \"summary\": \"Software Development Intern at Amazon Web Services (AWS), working from May 2024 to Aug 2024 on AWS Launch Wizard.\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Aneesh Seemakurthy\",\n",
            "      \"id\": \"https://www.linkedin.com/in/aneesh-seemakurthy/\",\n",
            "      \"pic\": \"https://media.licdn.com/dms/image/v2/D4E03AQGmSG5ID9ZDOw/profile-displayphoto-shrink_800_800/B4EZXuF4fLHUAc-/0/1743456274662?e=1749081600&v=beta&t=tLeFQORxEsG9DyHhktcCTj9XsNSD1dtiMKshSAZahQU\",\n",
            "      \"summary\": \"Software Development Engineer Intern at Amazon Web Services (AWS), working from May 2024 to Aug 2024 on Amazon Elastic Container Service (ECS).\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Sagar Gupta\",\n",
            "      \"id\": \"https://www.linkedin.com/in/sagar-gupta22/\",\n",
            "      \"pic\": \"https://media.licdn.com/dms/image/v2/D5603AQFl5NwPg1z33g/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1686024588837?e=1749081600&v=beta&t=n6s11xfV1NJcZUfs7P1fhS24aOVyiZGf3jJlzF1e1HE\",\n",
            "      \"summary\": \"Software Engineer Intern at Amazon, working from Jun 2024 to Aug 2024 on AWS Identity and Access Management (IAM).\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Asmita Karandikar\",\n",
            "      \"id\": \"https://www.linkedin.com/in/asmitakar/\",\n",
            "      \"pic\": \"https://media.licdn.com/dms/image/v2/D5603AQHqy4k-owFihQ/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1706672777404?e=1749081600&v=beta&t=52kAdQN3mdfkq6Hec9PTHq-e26lwqPvgsejsn0VrfIA\",\n",
            "      \"summary\": \"Software Development Engineer Intern at Amazon Web Services (AWS), working from May 2024 to Aug 2024.\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Pramod Chunduri\",\n",
            "      \"id\": \"https://www.linkedin.com/in/pramod-chunduri/\",\n",
            "      \"pic\": \"https://media.licdn.com/dms/image/v2/C4D03AQEzQFJVuNaxFw/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1618506670099?e=1749081600&v=beta&t=Q15FwWaz5CMb9dNbMYEOk5sT5SFh0BNX6pV2X_tL84U\",\n",
            "      \"summary\": \"Applied Scientist Intern at Amazon Web Services (AWS), working from May 2024 to Present, with skills in Large Language Models (LLM), Artificial Intelligence (AI), Natural Language Processing (NLP), and Information Retrieval.\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "input_message = \"Who works at Amazon from May 2024 to Aug 2024 with skills in AWS\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "88a4f0e3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Who works at Capital One?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (call_pXsUS0RpYOOo6QGjpY8ruf7r)\n",
            " Call ID: call_pXsUS0RpYOOo6QGjpY8ruf7r\n",
            "  Args:\n",
            "    query: Who worked at Capital One?\n",
            "Parsed search parameters: {'names': [], 'companies': ['Capital One'], 'titles': [], 'locations': [], 'duration': [], 'skills': []}\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "No matching alumni profiles found.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "{}\n"
          ]
        }
      ],
      "source": [
        "input_message = \"Who works at Capital One?\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "ff592021",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Who is Yihao? What are his experiences?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (00df2b14-63ef-4012-86e5-a31f7b58cfea)\n",
            " Call ID: 00df2b14-63ef-4012-86e5-a31f7b58cfea\n",
            "  Args:\n",
            "    query: Yihao, experience\n",
            "Extracted parameters: {'companies': [], 'names': ['Yihao']}\n",
            "Search parameters: companies=[], names=['Yihao']\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "1. Content: Yihao Mai is a Incoming SDE intern @ Tyler Technologies  | BSMS CS @ Georgia Tech at Lawrenceville, Georgia, United States. Yihao Mai self-describes as I'm a fourth-year BSMS CS student at Georgia Tech with a strong passion for full-stack development, data management, and AI. Through various internships, projects, and research experiences, I have honed my skills in Java, Python, JavaScript, and frameworks such as React and Spring Boot. I also thrive in collaborative environments and am dedicated to continuous learning, staying up-to-date with the latest technologies to drive innovation and solve complex problems. I am actively seeking a Software Engineer internship opportunity to apply my skills and contribute to impactful projects.\n",
            "Id: https://www.linkedin.com/in/yihaomai/\n",
            " Name: Yihao Mai\n",
            " Profile Pic: https://media.licdn.com/dms/image/v2/D4E03AQHaMti75QWKWw/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1726084969563?e=1749081600&v=beta&t=GYU8iD5-FVlYm0xiP0j2AqQUstcFHr27RbykSdlwuu8\n",
            " Section: summary\n",
            "\n",
            "2. Content: Role: Research Software Engineer Intern, \n",
            "Company: IBM, \n",
            "Work Type: Internship, \n",
            "Location: Unknown, \n",
            "Duration: May 2024 to Jul 2024, \n",
            "Description: • Collaborated with an IBM research team to achieve compliance-as-code automation in the Compliance Trestle open-source project, resulting in 1000+ LOCs, 10+ closed issues, 15k monthly downloads\n",
            "\n",
            "• Identified and resolved bugs with Python to improve the project’s stability\n",
            "\n",
            "• Refactored the project’s webpage and CLI documentation\n",
            "\n",
            "• Updated existing demos to the latest Trestle version and added new demos to address additional use cases\n",
            "\n",
            "• Independently implemented Tekton pipelines to replace existing GitHub Action pipelines for a sub-project, addressing internal restrictions and ensuring the project's pipeline remained operational.\n",
            "Id: https://www.linkedin.com/in/yihaomai/\n",
            " Name: Yihao Mai\n",
            " Profile Pic: https://media.licdn.com/dms/image/v2/D4E03AQHaMti75QWKWw/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1726084969563?e=1749081600&v=beta&t=GYU8iD5-FVlYm0xiP0j2AqQUstcFHr27RbykSdlwuu8\n",
            " Section: work\n",
            " Company: IBM\n",
            "\n",
            "3. Content: School: CodePath, \n",
            "Degree: Certificate in Advanced Technical Interview Prep, \n",
            "Major: Unknown, \n",
            "Duration: Sep 2024 to Unknown, \n",
            "Description: Unknown.\n",
            "Id: https://www.linkedin.com/in/yihaomai/\n",
            " Name: Yihao Mai\n",
            " Profile Pic: https://media.licdn.com/dms/image/v2/D4E03AQHaMti75QWKWw/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1726084969563?e=1749081600&v=beta&t=GYU8iD5-FVlYm0xiP0j2AqQUstcFHr27RbykSdlwuu8\n",
            " Section: edu\n",
            " School: CodePath\n",
            "\n",
            "4. Content: School: Georgia Institute of Technology, \n",
            "Degree: Master's degree, \n",
            "Major: Computer Science, \n",
            "Duration: Jan 2025 to May 2026, \n",
            "Description: Unknown.\n",
            "Id: https://www.linkedin.com/in/yihaomai/\n",
            " Name: Yihao Mai\n",
            " Profile Pic: https://media.licdn.com/dms/image/v2/D4E03AQHaMti75QWKWw/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1726084969563?e=1749081600&v=beta&t=GYU8iD5-FVlYm0xiP0j2AqQUstcFHr27RbykSdlwuu8\n",
            " Section: edu\n",
            " School: Georgia Institute of Technology\n",
            "\n",
            "5. Content: School: Georgia Institute of Technology, \n",
            "Degree: Bachelor's degree, \n",
            "Major: Computer Science, \n",
            "Duration: Aug 2022 to May 2025, \n",
            "Description: Grade: Senior.\n",
            "Id: https://www.linkedin.com/in/yihaomai/\n",
            " Name: Yihao Mai\n",
            " Profile Pic: https://media.licdn.com/dms/image/v2/D4E03AQHaMti75QWKWw/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1726084969563?e=1749081600&v=beta&t=GYU8iD5-FVlYm0xiP0j2AqQUstcFHr27RbykSdlwuu8\n",
            " Section: edu\n",
            " School: Georgia Institute of Technology\n",
            "\n",
            "6. Content: Role: Undergraduate Research Assistant, \n",
            "Company: Georgia Institute of Technology, \n",
            "Work Type: Part-time, \n",
            "Location: Atlanta, Georgia, United States · On-site, \n",
            "Duration: Aug 2024 to Present, \n",
            "Description: • Undergraduate Research Assistant at the Data to Insights (D2I) lab\n",
            "\n",
            "• Designed database schemas and structured millions of OpenAlex research records in Azure PostgreSQL, enabling self-controlled data management and serving as the primary data source for the funded CollabNext project\n",
            "\n",
            "• Leveraged EXPLAIN ANALYZE to refine queries and created materialized views to cache complex query results, reducing runtime from seconds to milliseconds, a 90% speedup\n",
            "\n",
            "•  Defined ontology mapping schemas and utilized Ontop to convert billions of relational data into RDF format, significantly enhancing the product's scalability and enabling advanced semantic queries.\n",
            "Id: https://www.linkedin.com/in/yihaomai/\n",
            " Name: Yihao Mai\n",
            " Profile Pic: https://media.licdn.com/dms/image/v2/D4E03AQHaMti75QWKWw/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1726084969563?e=1749081600&v=beta&t=GYU8iD5-FVlYm0xiP0j2AqQUstcFHr27RbykSdlwuu8\n",
            " Section: work\n",
            " Company: Georgia Institute of Technology\n",
            "\n",
            "7. Content: Role: Full Stack Developer Intern, \n",
            "Company: JobOclock, \n",
            "Work Type: Internship, \n",
            "Location: Unknown, \n",
            "Duration: Aug 2024 to Present, \n",
            "Description: • Designed, implemented, and deployed a Spring Boot email server on AWS EC2 to manage virtual email addresses for users and enabled internal staff to query and forward key information—such as verification codes and links—from application emails, streamlining the application process and reducing manual effort for users applying to hundreds of jobs\n",
            "\n",
            "• Developed an automated email processing pipeline using AWS SES, S3, and Lambda to extract and store critical information (e.g., sender company, verification links/codes) in DynamoDB for efficient data access and application follow-up communication.\n",
            "Id: https://www.linkedin.com/in/yihaomai/\n",
            " Name: Yihao Mai\n",
            " Profile Pic: https://media.licdn.com/dms/image/v2/D4E03AQHaMti75QWKWw/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1726084969563?e=1749081600&v=beta&t=GYU8iD5-FVlYm0xiP0j2AqQUstcFHr27RbykSdlwuu8\n",
            " Section: work\n",
            " Company: JobOclock\n",
            "\n",
            "8. Content: Role: Backend Developer, \n",
            "Company: uniBuzzy, \n",
            "Work Type: Part-time, \n",
            "Location: Atlanta, Georgia, United States · On-site, \n",
            "Duration: Mar 2024 to Oct 2024, \n",
            "Description: • Created a social media server with Spring Boot by setting entity models, API routes, and service methods, as well as user authentication with Firebase\n",
            "\n",
            "• Generated database schemas and applying them to the cloud-hosting CockroachDB through Hibernate ORM\n",
            "\n",
            "• Used stored procedures, batch deletes, and updates in the native query to support larger traffic\n",
            "\n",
            "• Wrote unit and integration tests with JUnit and Mockito.\n",
            "Id: https://www.linkedin.com/in/yihaomai/\n",
            " Name: Yihao Mai\n",
            " Profile Pic: https://media.licdn.com/dms/image/v2/D4E03AQHaMti75QWKWw/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1726084969563?e=1749081600&v=beta&t=GYU8iD5-FVlYm0xiP0j2AqQUstcFHr27RbykSdlwuu8\n",
            " Section: work\n",
            " Company: uniBuzzy\n",
            "\n",
            "9. Content: Role: Software Development Intern, \n",
            "Company: Tyler Technologies, \n",
            "Work Type: Internship, \n",
            "Location: Lawrenceville, Georgia, United States · On-site, \n",
            "Duration: Mar 2025 to Present, \n",
            "Description: Incoming summer 2025 SDE intern.\n",
            "Id: https://www.linkedin.com/in/yihaomai/\n",
            " Name: Yihao Mai\n",
            " Profile Pic: https://media.licdn.com/dms/image/v2/D4E03AQHaMti75QWKWw/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1726084969563?e=1749081600&v=beta&t=GYU8iD5-FVlYm0xiP0j2AqQUstcFHr27RbykSdlwuu8\n",
            " Section: work\n",
            " Company: Tyler Technologies\n",
            "\n",
            "\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "{\n",
            "  \"alumni\": [\n",
            "    {\n",
            "      \"name\": \"Yihao Mai\",\n",
            "      \"id\": \"https://www.linkedin.com/in/yihaomai/\",\n",
            "      \"summary\": \"\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "\n",
            "Based on the provided document, Yihao is a young professional with multiple internship and part-time work experiences in various fields including software development, backend development, and full-stack development. \n",
            "\n",
            "Here's a brief summary of his experience:\n",
            "\n",
            "* He had an internship as a Full Stack Developer at JobOclock from August 2024 to Present.\n",
            "* He worked as a Backend Developer at uniBuzzy from March 2024 to October 2024.\n",
            "* He also interned at Tyler Technologies as a Software Development Intern, starting in March 2025.\n"
          ]
        }
      ],
      "source": [
        "input_message = \"Who is Yihao? What are his experiences?\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "79cc4419",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Who is currently working at Amazon as an intern?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (call_PxV2HPQZLk0EuEHQk47DtnGz)\n",
            " Call ID: call_PxV2HPQZLk0EuEHQk47DtnGz\n",
            "  Args:\n",
            "    query: Who is working at Amazon as a intern?\n",
            "Parsed search parameters: { \"names\": [], \"companies\": [\"Amazon\"], \"titles\": [\"intern\"], \"locations\": [], \"duration\": [] }\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "1. Content: Name: Yoon Ji Cho\n",
            "Role: Software Engineering Intern\n",
            "Company: Amazon\n",
            "Work Type: Internship\n",
            "Location: Bellevue, Washington, United States · Hybrid\n",
            "Duration: Sep 2024 to Nov 2024\n",
            "Description: Digital Acceleration\n",
            "• Expedited Amazon digital product launches by automating the accounting approval process for business/finance teams.\n",
            "• Designed/implemented APIs to fetch test execution details and displayed on a frontend console for signoff.\n",
            "Id: https://www.linkedin.com/in/yoon-ji-cho/\n",
            "Name: Yoon Ji Cho\n",
            "Profile Pic: https://media.licdn.com/dms/image/v2/D4E03AQHJDa-KXfqRRg/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1713650348801?e=1749081600&v=beta&t=OG8KkldjZbTOPQ96pRoXOaVsgie9AygYbqpD8Y9_1xE\n",
            "\n",
            "2. Content: Name: Yanzhu Huang\n",
            "Role: Software Development Engineer Intern\n",
            "Company: Amazon\n",
            "Work Type: Internship\n",
            "Location: Sunnyvale, California, United States · On-site\n",
            "Duration: Aug 2024 to Present\n",
            "Description: Skills: Python (Programming Language) · Amazon Web Services (AWS)\n",
            "Id: https://www.linkedin.com/in/yanzhu-huang/\n",
            "Name: Yanzhu Huang\n",
            "Profile Pic: https://media.licdn.com/dms/image/v2/C5603AQFDwQxmq2Iphg/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1660136580169?e=1749081600&v=beta&t=NqdCz1pMdC3vr2xMpXe43mJCoxrJBX5JpSrB7-SYWRY\n",
            "\n",
            "3. Content: Name: Emily Liu\n",
            "Role: Software Development Intern\n",
            "Company: Amazon Web Services (AWS)\n",
            "Work Type: Internship\n",
            "Location: Unknown\n",
            "Duration: May 2024 to Aug 2024\n",
            "Description: AWS Launch Wizard\n",
            "Id: https://www.linkedin.com/in/emilyliu9/\n",
            "Name: Emily Liu\n",
            "Profile Pic: https://media.licdn.com/dms/image/v2/D5603AQFabemXZCe9ig/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1689139490004?e=1749081600&v=beta&t=0NKPmfwoSqAWhc5sRSpe2gdx4xwSUN_2UA7rSjUSPBk\n",
            "\n",
            "4. Content: Name: Samuel Chen\n",
            "Role: Software Development Intern\n",
            "Company: Amazon\n",
            "Work Type: Internship\n",
            "Location: Unknown\n",
            "Duration: Jul 2021 to Oct 2021\n",
            "Description: Unknown\n",
            "Id: https://www.linkedin.com/in/woshisam/\n",
            "Name: Samuel Chen\n",
            "Profile Pic: https://media.licdn.com/dms/image/v2/D4E03AQHHdFI6-2oazw/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1709054767501?e=1749081600&v=beta&t=2-gNOV4zDT-5KEvpcTNrivUzsWyXrtGoczW0YhUlmTs\n",
            "\n",
            "5. Content: Name: Carlos Tellez\n",
            "Role: Area Manager Intern\n",
            "Company: Amazon\n",
            "Work Type: Internship\n",
            "Location: Jackson, Mississippi, United States · On-site\n",
            "Duration: May 2024 to Jul 2024\n",
            "Description: Spearheaded a 5S project to improve the safety, organization, and overall efficiency of the Amazon Fulfillment Engine.\n",
            "Id: https://www.linkedin.com/in/carlos-tellez319/\n",
            "Name: Carlos Tellez\n",
            "Profile Pic: https://media.licdn.com/dms/image/v2/D5603AQG1SpO3hHBpFA/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1714676348494?e=1749081600&v=beta&t=ktqnqEOsPe5fchzgeNqrA2voei1WLE4li_P1FD7NF4c\n",
            "\n",
            "6. Content: Name: Jonathan Le\n",
            "Role: Software Development Engineer Intern, Amazon SageMaker\n",
            "Company: Amazon Web Services (AWS)\n",
            "Work Type: Internship\n",
            "Location: Greater Seattle Area\n",
            "Duration: May 2024 to Aug 2024\n",
            "Description: Skills: Amazon Web Services (AWS) · Java\n",
            "Id: https://www.linkedin.com/in/jonathanvanle/\n",
            "Name: Jonathan Le\n",
            "Profile Pic: https://media.licdn.com/dms/image/v2/D4E03AQEDiRaAATGS_g/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1718213718392?e=1749081600&v=beta&t=sS8D0pZlrHPAY_kz2j-q8tmjFh1jkG9qyXQGN9tCflY\n",
            "\n",
            "7. Content: Name: Arnav Patidar\n",
            "Role: Software Development Engineer Intern\n",
            "Company: Amazon\n",
            "Work Type: Internship\n",
            "Location: New York, New York, United States\n",
            "Duration: May 2024 to Aug 2024\n",
            "Description: Ads - Publisher Technology\n",
            "\n",
            "Skills:Java · Python (Programming Language) · Elasticsearch · API Development · QueryDSL · Software Development Life Cycle (SDLC)\n",
            "Id: https://www.linkedin.com/in/arnavpatidar\n",
            "Name: Arnav Patidar\n",
            "Profile Pic: https://media.licdn.com/dms/image/v2/D4E03AQG0gY6hPjZEjg/profile-displayphoto-shrink_200_200/profile-displayphoto-shrink_200_200/0/1668463395069?e=1747872000&v=beta&t=2-vwzRO8gbZAZ5NEtKpXO6-vH9FJ_wvXikU2boYH9BY\n",
            "\n",
            "8. Content: Name: Timothy Bang\n",
            "Role: Software Development Engineer Intern\n",
            "Company: Amazon\n",
            "Work Type: Internship\n",
            "Location: Seattle, Washington, United States · Hybrid\n",
            "Duration: May 2022 to Aug 2022\n",
            "Description: Fulfilling APIs for Binding Inventory and Moving & Unbinding Inventory in Amazon's Physical Stores\n",
            "Id: https://www.linkedin.com/in/timothybang/\n",
            "Name: Timothy Bang\n",
            "Profile Pic: Unknown\n",
            "\n",
            "9. Content: Name: Luca Gianantonio\n",
            "Role: SDE Intern at Amazon\n",
            "Company: Amazon\n",
            "Work Type: Unknown\n",
            "Location: Bellevue, Washington, United States · On-site\n",
            "Duration: May 2023 to Aug 2023\n",
            "Description: • Collaborated with the Alexa Audio team, contributing to a significant project focused on the automatic triaging of cloud services.\n",
            "• Conducted thorough testing and quality assurance procedures to identify and resolve issues, ensuring the reliability and robustness of the software.\n",
            "• Demonstrated strong problem-solving skills and adaptability while working in a dynamic and fast-paced environment.\n",
            "Id: https://www.linkedin.com/in/luca-gianantonio/\n",
            "Name: Luca Gianantonio\n",
            "Profile Pic: https://media.licdn.com/dms/image/v2/D4D03AQHzWLlxAsqVLw/profile-displayphoto-shrink_800_800/B4DZUk2VUuHkAc-/0/1740079980490?e=1749081600&v=beta&t=-asO2RPpjkxqKZ_ZLMRmrnvh6DBzhjDc7ulzE_apYm8\n",
            "\n",
            "10. Content: Name: Arkin Worlikar\n",
            "Role: SDE Intern\n",
            "Company: Amazon\n",
            "Work Type: Internship\n",
            "Location: Seattle, Washington, United States · On-site\n",
            "Duration: May 2024 to Aug 2024\n",
            "Description: Unknown\n",
            "Id: https://www.linkedin.com/in/arkin-worlikar/\n",
            "Name: Arkin Worlikar\n",
            "Profile Pic: https://media.licdn.com/dms/image/v2/D5603AQFLGqWDc5r17Q/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1693865947409?e=1749081600&v=beta&t=eotcf_az5H52IMgPi8y3wu3pytvmVAmThTywodjrT6U\n",
            "\n",
            "11. Content: Name: Thomas Tan\n",
            "Role: Software Engineer Intern\n",
            "Company: Amazon\n",
            "Work Type: Internship\n",
            "Location: Seattle, Washington, United States\n",
            "Duration: Jan 2020 to May 2020\n",
            "Description: Unknown\n",
            "Id: https://www.linkedin.com/in/kok-wei-thomas-tan/\n",
            "Name: Thomas Tan\n",
            "Profile Pic: Unknown\n",
            "\n",
            "12. Content: Name: Ishaan Bhardwaj\n",
            "Role: Software Development Engineering Intern\n",
            "Company: Amazon\n",
            "Work Type: Full-time\n",
            "Location: New York City Metropolitan Area · On-site\n",
            "Duration: Mar 2025 to Present\n",
            "Description: Unknown\n",
            "Id: https://www.linkedin.com/in/ishaan-bhardwaj12/\n",
            "Name: Ishaan Bhardwaj\n",
            "Profile Pic: https://media.licdn.com/dms/image/v2/D4D03AQEcVZ1L5FcgpA/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1732293266902?e=1749081600&v=beta&t=hHBd73wH0Q24xMJnfqa3altJeY3wAFFqKTTWVBDFAqg\n",
            "\n",
            "13. Content: Name: Asmita Karandikar\n",
            "Role: Software Development Engineer Intern\n",
            "Company: Amazon Web Services (AWS)\n",
            "Work Type: Internship\n",
            "Location: Seattle, Washington, United States · On-site\n",
            "Duration: May 2024 to Aug 2024\n",
            "Description: Unknown\n",
            "Id: https://www.linkedin.com/in/asmitakar/\n",
            "Name: Asmita Karandikar\n",
            "Profile Pic: https://media.licdn.com/dms/image/v2/D5603AQHqy4k-owFihQ/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1706672777404?e=1749081600&v=beta&t=52kAdQN3mdfkq6Hec9PTHq-e26lwqPvgsejsn0VrfIA\n",
            "\n",
            "14. Content: Name: Eric Ming\n",
            "Role: Software Engineer Intern\n",
            "Company: Amazon\n",
            "Work Type: Internship\n",
            "Location: Seattle, Washington, United States\n",
            "Duration: May 2022 to Aug 2022\n",
            "Description: Unknown\n",
            "Id: https://www.linkedin.com/in/eric-ming/\n",
            "Name: Eric Ming\n",
            "Profile Pic: https://media.licdn.com/dms/image/v2/D4E03AQH80RBvsK5uJg/profile-displayphoto-shrink_400_400/profile-displayphoto-shrink_400_400/0/1686842667675?e=1749081600&v=beta&t=bVtuE5m_-Blc-rw7c8orIR2qvrL-soQ-eJBqmZCZT3g\n",
            "\n",
            "15. Content: Name: William Tjokroamidjojo\n",
            "Role: Software Development Engineer Intern\n",
            "Company: Amazon\n",
            "Work Type: Unknown\n",
            "Location: Austin, Texas, United States\n",
            "Duration: May 2024 to Aug 2024\n",
            "Description: Skills: Amazon Web Services (AWS)\n",
            "Id: https://www.linkedin.com/in/william-tjokroamidjojo/\n",
            "Name: William Tjokroamidjojo\n",
            "Profile Pic: https://media.licdn.com/dms/image/v2/D4E03AQEIh5fVaT_-lA/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1690842342466?e=1749081600&v=beta&t=4vMBsI_TdxH56ua6eUESn3GomYw3hxlxM2ysN4kxo48\n",
            "\n",
            "\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "{\n",
            "  \"alumni\": [\n",
            "    {\n",
            "      \"name\": \"Yoon Ji Cho\",\n",
            "      \"id\": \"https://www.linkedin.com/in/yoon-ji-cho/\",\n",
            "      \"pic\": \"https://media.licdn.com/dms/image/v2/D4E03AQHJDa-KXfqRRg/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1713650348801?e=1749081600&v=beta&t=OG8KkldjZbTOPQ96pRoXOaVsgie9AygYbqpD8Y9_1xE\",\n",
            "      \"summary\": \"Software Engineering Intern at Amazon, working on Digital Acceleration to expedite product launches by automating accounting processes and designing APIs.\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Yanzhu Huang\",\n",
            "      \"id\": \"https://www.linkedin.com/in/yanzhu-huang/\",\n",
            "      \"pic\": \"https://media.licdn.com/dms/image/v2/C5603AQFDwQxmq2Iphg/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1660136580169?e=1749081600&v=beta&t=NqdCz1pMdC3vr2xMpXe43mJCoxrJBX5JpSrB7-SYWRY\",\n",
            "      \"summary\": \"Software Development Engineer Intern at Amazon, currently working on-site with skills in Python and Amazon Web Services (AWS).\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Emily Liu\",\n",
            "      \"id\": \"https://www.linkedin.com/in/emilyliu9/\",\n",
            "      \"pic\": \"https://media.licdn.com/dms/image/v2/D5603AQFabemXZCe9ig/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1689139490004?e=1749081600&v=beta&t=0NKPmfwoSqAWhc5sRSpe2gdx4xwSUN_2UA7rSjUSPBk\",\n",
            "      \"summary\": \"Software Development Intern at Amazon Web Services (AWS), working on AWS Launch Wizard.\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Carlos Tellez\",\n",
            "      \"id\": \"https://www.linkedin.com/in/carlos-tellez319/\",\n",
            "      \"pic\": \"https://media.licdn.com/dms/image/v2/D5603AQG1SpO3hHBpFA/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1714676348494?e=1749081600&v=beta&t=ktqnqEOsPe5fchzgeNqrA2voei1WLE4li_P1FD7NF4c\",\n",
            "      \"summary\": \"Area Manager Intern at Amazon, leading a 5S project to enhance safety and efficiency in the Fulfillment Engine.\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Jonathan Le\",\n",
            "      \"id\": \"https://www.linkedin.com/in/jonathanvanle/\",\n",
            "      \"pic\": \"https://media.licdn.com/dms/image/v2/D4E03AQEDiRaAATGS_g/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1718213718392?e=1749081600&v=beta&t=sS8D0pZlrHPAY_kz2j-q8tmjFh1jkG9qyXQGN9tCflY\",\n",
            "      \"summary\": \"Software Development Engineer Intern at Amazon SageMaker, focusing on Amazon Web Services (AWS) and Java.\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Arnav Patidar\",\n",
            "      \"id\": \"https://www.linkedin.com/in/arnavpatidar\",\n",
            "      \"pic\": \"https://media.licdn.com/dms/image/v2/D4E03AQG0gY6hPjZEjg/profile-displayphoto-shrink_200_200/profile-displayphoto-shrink_200_200/0/1668463395069?e=1747872000&v=beta&t=2-vwzRO8gbZAZ5NEtKpXO6-vH9FJ_wvXikU2boYH9BY\",\n",
            "      \"summary\": \"Software Development Engineer Intern at Amazon, working on Ads - Publisher Technology with skills in Java, Python, and API Development.\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Timothy Bang\",\n",
            "      \"id\": \"https://www.linkedin.com/in/timothybang/\",\n",
            "      \"pic\": \"Unknown\",\n",
            "      \"summary\": \"Software Development Engineer Intern at Amazon, involved in fulfilling APIs for inventory management in physical stores.\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Luca Gianantonio\",\n",
            "      \"id\": \"https://www.linkedin.com/in/luca-gianantonio/\",\n",
            "      \"pic\": \"https://media.licdn.com/dms/image/v2/D4D03AQHzWLlxAsqVLw/profile-displayphoto-shrink_800_800/B4DZUk2VUuHkAc-/0/1740079980490?e=1749081600&v=beta&t=-asO2RPpjkxqKZ_ZLMRmrnvh6DBzhjDc7ulzE_apYm8\",\n",
            "      \"summary\": \"SDE Intern at Amazon, collaborating with the Alexa Audio team on cloud services triaging and quality assurance.\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Arkin Worlikar\",\n",
            "      \"id\": \"https://www.linkedin.com/in/arkin-worlikar/\",\n",
            "      \"pic\": \"https://media.licdn.com/dms/image/v2/D5603AQFLGqWDc5r17Q/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1693865947409?e=1749081600&v=beta&t=eotcf_az5H52IMgPi8y3wu3pytvmVAmThTywodjrT6U\",\n",
            "      \"summary\": \"SDE Intern at Amazon, currently working on-site.\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Ishaan Bhardwaj\",\n",
            "      \"id\": \"https://www.linkedin.com/in/ishaan-bhardwaj12/\",\n",
            "      \"pic\": \"https://media.licdn.com/dms/image/v2/D4D03AQEcVZ1L5FcgpA/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1732293266902?e=1749081600&v=beta&t=hHBd73wH0Q24xMJnfqa3altJeY3wAFFqKTTWVBDFAqg\",\n",
            "      \"summary\": \"Software Development Engineering Intern at Amazon, currently working full-time.\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"William Tjokroamidjojo\",\n",
            "      \"id\": \"https://www.linkedin.com/in/william-tjokroamidjojo/\",\n",
            "      \"pic\": \"https://media.licdn.com/dms/image/v2/D4E03AQEIh5fVaT_-lA/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1690842342466?e=1749081600&v=beta&t=4vMBsI_TdxH56ua6eUESn3GomYw3hxlxM2ysN4kxo48\",\n",
            "      \"summary\": \"Software Development Engineer Intern at Amazon, with skills in Amazon Web Services (AWS).\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "input_message = \"Who is currently working at Amazon as an intern?\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a26a9c4d-0e5b-4db9-8b78-68624d829ac2",
      "metadata": {
        "id": "a26a9c4d-0e5b-4db9-8b78-68624d829ac2"
      },
      "source": [
        "Check out the LangSmith trace [here](https://smith.langchain.com/public/70110399-01d3-4b4b-9139-cbcd4edf9d6d/r)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d9d16f8",
      "metadata": {},
      "source": [
        "# I haven't modified below code for our model, just skip them"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2300c04-019c-4c65-a104-3dbf17c924b7",
      "metadata": {
        "id": "c2300c04-019c-4c65-a104-3dbf17c924b7"
      },
      "source": [
        "### Stateful management of chat history\n",
        "\n",
        ":::note\n",
        "\n",
        "This section of the tutorial previously used the [RunnableWithMessageHistory](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html) abstraction. You can access that version of the documentation in the [v0.2 docs](https://python.langchain.com/v0.2/docs/tutorials/chatbot/).\n",
        "\n",
        "As of the v0.3 release of LangChain, we recommend that LangChain users take advantage of [LangGraph persistence](https://langchain-ai.github.io/langgraph/concepts/persistence/) to incorporate `memory` into new LangChain applications.\n",
        "\n",
        "If your code is already relying on `RunnableWithMessageHistory` or `BaseChatMessageHistory`, you do **not** need to make any changes. We do not plan on deprecating this functionality in the near future as it works for simple chat applications and any code that uses `RunnableWithMessageHistory` will continue to work as expected.\n",
        "\n",
        "Please see [How to migrate to LangGraph Memory](/docs/versions/migrating_memory/) for more details.\n",
        ":::\n",
        "\n",
        "In production, the Q&A application will usually persist the chat history into a database, and be able to read and update it appropriately.\n",
        "\n",
        "[LangGraph](https://langchain-ai.github.io/langgraph/) implements a built-in [persistence layer](https://langchain-ai.github.io/langgraph/concepts/persistence/), making it ideal for chat applications that support multiple conversational turns.\n",
        "\n",
        "To manage multiple conversational turns and threads, all we have to do is specify a [checkpointer](https://langchain-ai.github.io/langgraph/concepts/persistence/) when compiling our application. Because the nodes in our graph are appending messages to the state, we will retain a consistent chat history across invocations.\n",
        "\n",
        "LangGraph comes with a simple in-memory checkpointer, which we use below. See its [documentation](https://langchain-ai.github.io/langgraph/concepts/persistence/) for more detail, including how to use different persistence backends (e.g., SQLite or Postgres).\n",
        "\n",
        "For a detailed walkthrough of how to manage message history, head to the [How to add message history (memory)](/docs/how_to/message_history) guide."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "e5cd784a-61b2-4f9c-ad92-3e555b33d0bf",
      "metadata": {
        "id": "e5cd784a-61b2-4f9c-ad92-3e555b33d0bf"
      },
      "outputs": [],
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "memory = MemorySaver()\n",
        "graph = graph_builder.compile(checkpointer=memory)\n",
        "\n",
        "# Specify an ID for the thread\n",
        "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f557b169-b33c-42d0-b97e-1b948d0a2914",
      "metadata": {
        "id": "f557b169-b33c-42d0-b97e-1b948d0a2914"
      },
      "source": [
        "We can now invoke similar to before:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6d16477-52f5-4755-83d1-60eebddfaaa0",
      "metadata": {
        "id": "c6d16477-52f5-4755-83d1-60eebddfaaa0",
        "outputId": "cbea0a06-96f3-417c-9293-8dec344ad20e"
      },
      "outputs": [],
      "source": [
        "input_message = \"What is Task Decomposition?\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "    config=config,\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9d6f0ee-b5a9-4141-9f6f-ad86a04e083f",
      "metadata": {
        "id": "c9d6f0ee-b5a9-4141-9f6f-ad86a04e083f",
        "outputId": "1bb7baeb-7374-4294-bac3-bb8da1b5fcfe"
      },
      "outputs": [],
      "source": [
        "input_message = \"Can you look up some common ways of doing it?\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "    config=config,\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bbbeef2-d9a1-4857-874f-9f3b5cc4eca9",
      "metadata": {
        "id": "4bbbeef2-d9a1-4857-874f-9f3b5cc4eca9"
      },
      "source": [
        "Note that the query generated by the model in the second question incorporates the conversational context.\n",
        "\n",
        "The [LangSmith](https://smith.langchain.com/public/28e6179f-fc56-45e1-9028-447d76352c14/r) trace is particularly informative here, as we can see exactly what messages are visible to our chat model at each step."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ad23c71-3c99-4d9d-b494-9b7a08a557c0",
      "metadata": {
        "id": "0ad23c71-3c99-4d9d-b494-9b7a08a557c0"
      },
      "source": [
        "## Agents {#agents}\n",
        "\n",
        "[Agents](/docs/concepts/agents) leverage the reasoning capabilities of LLMs to make decisions during execution. Using agents allows you to offload additional discretion over the retrieval process. Although their behavior is less predictable than the above \"chain\", they are able to execute multiple retrieval steps in service of a query, or iterate on a single search.\n",
        "\n",
        "Below we assemble a minimal RAG agent. Using LangGraph's [pre-built ReAct agent constructor](https://langchain-ai.github.io/langgraph/how-tos/#langgraph.prebuilt.chat_agent_executor.create_react_agent), we can do this in one line.\n",
        "\n",
        ":::tip\n",
        "\n",
        "Check out LangGraph's [Agentic RAG](https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_agentic_rag/) tutorial for more advanced formulations.\n",
        "\n",
        ":::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "470d5996-527d-4ef1-9e31-2c259cc3c050",
      "metadata": {
        "id": "470d5996-527d-4ef1-9e31-2c259cc3c050"
      },
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "agent_executor = create_react_agent(llm, [retrieve], checkpointer=memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d8f8734-5dcf-4058-a532-11c8a7d0efae",
      "metadata": {
        "id": "7d8f8734-5dcf-4058-a532-11c8a7d0efae"
      },
      "source": [
        "Let's inspect the graph:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0907cef3-05cb-45c7-ab46-382c58c52eb1",
      "metadata": {
        "id": "0907cef3-05cb-45c7-ab46-382c58c52eb1",
        "outputId": "01030df6-a7b8-4779-9134-e5aa4bc8546b"
      },
      "outputs": [],
      "source": [
        "display(Image(agent_executor.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28623a52-7906-440f-8aaf-d6bb5ecbad98",
      "metadata": {
        "id": "28623a52-7906-440f-8aaf-d6bb5ecbad98"
      },
      "source": [
        "The key difference from our earlier implementation is that instead of a final generation step that ends the run, here the tool invocation loops back to the original LLM call. The model can then either answer the question using the retrieved context, or generate another tool call to obtain more information.\n",
        "\n",
        "Let's test this out. We construct a question that would typically require an iterative sequence of retrieval steps to answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2f48f92-bd91-4033-a01b-7bd0667e3d87",
      "metadata": {
        "id": "a2f48f92-bd91-4033-a01b-7bd0667e3d87",
        "outputId": "b2e22740-eef6-431f-dd0a-dbf7e2db622f"
      },
      "outputs": [],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"def234\"}}\n",
        "\n",
        "input_message = (\n",
        "    \"What is the standard method for Task Decomposition?\\n\\n\"\n",
        "    \"Once you get the answer, look up common extensions of that method.\"\n",
        ")\n",
        "\n",
        "for event in agent_executor.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "    config=config,\n",
        "):\n",
        "    event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47ab58d2-92ef-4940-a535-7c8808e75523",
      "metadata": {
        "id": "47ab58d2-92ef-4940-a535-7c8808e75523"
      },
      "source": [
        "Note that the agent:\n",
        "\n",
        "1. Generates a query to search for a standard method for task decomposition;\n",
        "2. Receiving the answer, generates a second query to search for common extensions of it;\n",
        "3. Having received all necessary context, answers the question.\n",
        "\n",
        "We can see the full sequence of steps, along with latency and other metadata, in the [LangSmith trace](https://smith.langchain.com/public/48cbd35e-9ac1-49ab-8c09-500d54c06b81/r).\n",
        "\n",
        "## Next steps\n",
        "\n",
        "We've covered the steps to build a basic conversational Q&A application:\n",
        "\n",
        "- We used chains to build a predictable application that generates at most one query per user input;\n",
        "- We used agents to build an application that can iterate on a sequence of queries.\n",
        "\n",
        "To explore different types of retrievers and retrieval strategies, visit the [retrievers](/docs/how_to/#retrievers) section of the how-to guides.\n",
        "\n",
        "For a detailed walkthrough of LangChain's conversation memory abstractions, visit the [How to add message history (memory)](/docs/how_to/message_history) guide.\n",
        "\n",
        "To learn more about agents, check out the [conceptual guide](/docs/concepts/agents) and LangGraph [agent architectures](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/) page."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97b7c675-4011-43d2-9a6a-ddcf75fec536",
      "metadata": {
        "id": "97b7c675-4011-43d2-9a6a-ddcf75fec536"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
