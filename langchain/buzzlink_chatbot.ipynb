{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "487d8d79-5ee9-4aa4-9fdf-cd5f4303e099",
      "metadata": {
        "id": "487d8d79-5ee9-4aa4-9fdf-cd5f4303e099"
      },
      "source": [
        "## Setup\n",
        "\n",
        "### Components\n",
        "Generative Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "fab0dd56-7437-4aeb-af20-7f420d47ca94",
      "metadata": {
        "id": "fab0dd56-7437-4aeb-af20-7f420d47ca94"
      },
      "outputs": [],
      "source": [
        "from langchain_ollama import ChatOllama\n",
        "\n",
        "llm = ChatOllama(model=\"llama3.1:latest\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da14773e-ac98-4a97-944b-4c6ec028d195",
      "metadata": {
        "id": "da14773e-ac98-4a97-944b-4c6ec028d195"
      },
      "source": [
        "Embedding Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "4691bd31-d8f4-4ba1-aec5-44935400f33c",
      "metadata": {
        "id": "4691bd31-d8f4-4ba1-aec5-44935400f33c"
      },
      "outputs": [],
      "source": [
        "from langchain_ollama import OllamaEmbeddings\n",
        "\n",
        "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22fdc314-b91d-4820-b0a8-873b5b6e76f5",
      "metadata": {
        "id": "22fdc314-b91d-4820-b0a8-873b5b6e76f5"
      },
      "source": [
        "Vector Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "137d3848-7265-4673-9779-4c5f604da469",
      "metadata": {
        "id": "137d3848-7265-4673-9779-4c5f604da469"
      },
      "outputs": [],
      "source": [
        "# from langchain_core.vectorstores import InMemoryVectorStore\n",
        "\n",
        "# vector_store = InMemoryVectorStore(embeddings)\n",
        "from langchain_qdrant import QdrantVectorStore\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.models import Distance, VectorParams\n",
        "\n",
        "\n",
        "reuse_embedding = True\n",
        "# previous_vector_store = \"./user_profile_vector_store\"\n",
        "\n",
        "# new_vector_store = \"./user_profile_vector_store\"\n",
        "\n",
        "# vector_store = Chroma(\n",
        "#     collection_name=\"user_profile_vector_store\",\n",
        "#     embedding_function=embeddings,\n",
        "#     persist_directory=previous_vector_store if reload else new_vector_store,  # Where to save data locally, remove if not necessary\n",
        "    \n",
        "# )\n",
        "\n",
        "\n",
        "qdrant_client = QdrantClient(\n",
        "    url = \"https://6dfee087-1d0f-4a2c-97e3-d9dae27836bf.us-east-1-0.aws.cloud.qdrant.io\",\n",
        "    api_key= \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.I4HaiEeiATI7j2vYoYkKTFszON1OLs-ekegJqxmx-cw\"\n",
        "    ) \n",
        "\n",
        "collection_name = \"user_profile_collection\"\n",
        "collections = qdrant_client.get_collections()\n",
        "if collection_name not in [collection.name for collection in collections.collections]:\n",
        "    qdrant_client.create_collection(\n",
        "        collection_name=collection_name,\n",
        "        vectors_config=VectorParams(\n",
        "            size=768, \n",
        "            distance=Distance.COSINE \n",
        "        )\n",
        "    )\n",
        "    print(f\"Collection '{collection_name}' created successfully!\")\n",
        "\n",
        "vector_store = QdrantVectorStore(\n",
        "    client=qdrant_client,\n",
        "    collection_name=collection_name,\n",
        "    embedding=embeddings\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "156e5192",
      "metadata": {},
      "source": [
        "LangChain API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "92707666",
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "# LangChain API key: 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\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa6ba684-26cf-4860-904e-a4d51380c134",
      "metadata": {
        "id": "fa6ba684-26cf-4860-904e-a4d51380c134"
      },
      "source": [
        "## Steps\n",
        "### Indexing\n",
        "Load Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "ffe06d69-33c9-4ca3-98fb-8c70cde9dba2",
      "metadata": {
        "id": "ffe06d69-33c9-4ca3-98fb-8c70cde9dba2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1379\n",
            "page_content='{\"Id\": \"https://www.linkedin.com/in/clairejisun/\", \"Profile_Pic\": \"https://media.licdn.com/dms/image/v2/D4E03AQGg1lO8pJl0iw/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1710007158674?e=1749081600&v=beta&t=_XvJXwsKdK1kUd3LOKgmrnrdc2hWfBnLNGsdI2yFmic\", \"Name\": \"Jisun Kim\", \"About\": \"I am a 2nd year Mechanical Engineering student at Georgia Tech. I am currently researching medical/surgical robots as an undergraduate researcher at the BioMedical Mechatronics (BM2) Lab. I am working on the robot control and 3D design for different parts. I previously led a project, building a custom, low cost, and light weight prosthetic hand for an amputee without four fingers, securing $10K in funding.\\n\\nI also serve as the Event Director for the Korean-American Scientists & Engineers Association and have experience as Concertmaster for the Georgia Tech Symphony Orchestra. My skills include programming, CAD, and advanced manufacturing techniques, and I am fluent in English and Korean.\", \"Headline\": \"Flight Simulator Engineering Intern @Delta | ME @Georgia Tech | Presidential Science Scholar\", \"Location\": \"Atlanta, Georgia, United States\", \"Experiences\": [{\"Title\": \"Flight Simulator Engineering Intern\", \"Company\": \"Delta Air Lines\", \"Work_Type\": \"Internship\", \"Location\": \"Atlanta, Georgia, United States\", \"Description\": \"Skills: C (Programming Language)\", \"Duration\": {\"Start\": \"Jan 2025\", \"End\": \"Present\"}}, {\"Title\": \"Undergraduate Researcher at BioMedical Mechatronics (BM2) Lab\", \"Company\": \"Georgia Institute of Technology\", \"Work_Type\": \"\", \"Location\": \"Atlanta, Georgia, United States \\u00b7 On-site\", \"Description\": \"Prototyped and fabricated a component to securely connect and support the ultrasound probe to the surgical robot arm, withstanding the robot\\u2019s 7 degrees of freedom during surgery.\\nImplemented teleoperation code for the Stretch Robot's base and joint lift, harnessing its 10 degrees of freedom to develop a mobile robot assisting nurses in the ICU.\\nConducted literature review on robotic mapping and control to identify efficient algorithms enhancing the performance of the nurse-assisting mobile robot in the ICU.\", \"Duration\": {\"Start\": \"Sep 2023\", \"End\": \"Present\"}}, {\"Title\": \"Intro to Physics II Undergraduate Teaching Assistant\", \"Company\": \"Georgia Institute of Technology\", \"Work_Type\": \"\", \"Location\": \"\", \"Description\": \"Lead lab and group problem-solving sessions for 25 students in a Physics II (Electricity & Magnetism) course.\\nProvide individual assistance to students by answering questions, reinforcing course material and clarifying key concepts.\", \"Duration\": {\"Start\": \"Aug 2024\", \"End\": \"Dec 2024\"}}], \"Education\": [{\"School\": \"Georgia Institute of Technology\", \"Degree\": \"Bachelor's degree\", \"Major\": \"Mechanical Engineering\", \"Description\": \"\", \"Duration\": {\"Start\": \"Aug 2023\", \"End\": \"May 2027\"}}, {\"School\": \"Valor Christian High School\", \"Degree\": \"\", \"Major\": \"\", \"Description\": \"\", \"Duration\": {\"Start\": \"2019\", \"End\": \"2023\"}}]}' metadata={'source': '/Users/ma1h01/Desktop/Research/buzzlink/data/raw-profile-data/profile_data.json', 'seq_num': 1}\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import JSONLoader\n",
        "\n",
        "PATH = \"../data/raw-profile-data/profile_data.json\"\n",
        "\n",
        "jq_schema = '''\n",
        ".[] | \n",
        "{\n",
        "  Id: .id,\n",
        "  Profile_Pic: .profile_pic,\n",
        "  Name: .name,\n",
        "  About: .about,\n",
        "  Headline: .headline,\n",
        "  Location: .location,\n",
        "  Experiences: [\n",
        "    .experiences[] | {\n",
        "      Title: .title,\n",
        "      Company: .company,\n",
        "      Work_Type: .work_type,\n",
        "      Location: .location,\n",
        "      Description: .description,\n",
        "      Duration: {\n",
        "        Start: .start_date,\n",
        "        End: .end_date\n",
        "      }\n",
        "    }\n",
        "  ],\n",
        "  Education: [\n",
        "    .educations[] | {\n",
        "      School: .school,\n",
        "      Degree: .degree,\n",
        "      Major: .major,\n",
        "      Description: .description,\n",
        "      Duration: {\n",
        "        Start: .start_date,\n",
        "        End: .end_date\n",
        "      }\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "'''\n",
        "\n",
        "loader = JSONLoader(\n",
        "    file_path=PATH,\n",
        "    jq_schema=jq_schema,\n",
        "    text_content=False,\n",
        ")\n",
        "docs = loader.load()\n",
        "print(len(docs))\n",
        "print(docs[0])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "188ed897",
      "metadata": {},
      "source": [
        "Split long document list into chunks, if necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "f93e628a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "# all_splits = text_splitter.split_documents(docs)\n",
        "# print(len(all_splits))\n",
        "# print(all_splits[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71a0d8bb",
      "metadata": {},
      "source": [
        "Add additional metadata to the document object for later search filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "460758fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "def preprocess_doc(doc):\n",
        "    \"\"\"Preprocess document to extract and add metadata.\"\"\"\n",
        "    \n",
        "    # Parse the page_content if it's a string\n",
        "    if isinstance(doc.page_content, str):\n",
        "        content = json.loads(doc.page_content)\n",
        "    else:\n",
        "        content = doc.page_content\n",
        "        \n",
        "    # Extract all unique companies from experiences\n",
        "    companies = set()\n",
        "    for exp in content.get(\"Experiences\", []):\n",
        "        company = exp.get(\"Company\")\n",
        "        if company:\n",
        "            companies.add(company)\n",
        "    \n",
        "    # Add companies to metadata\n",
        "    doc.metadata[\"companies\"] = list(companies)\n",
        "    \n",
        "    return doc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed0919ca",
      "metadata": {},
      "source": [
        "Embed the document object lists and add them to the vector store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "b4369949-39f1-4cdc-b652-179e0b891b51",
      "metadata": {
        "id": "b4369949-39f1-4cdc-b652-179e0b891b51"
      },
      "outputs": [],
      "source": [
        "if not reuse_embedding:\n",
        "    processed_docs = [preprocess_doc(doc) for doc in docs]\n",
        "    print(f\"len(processed_docs): {len(processed_docs)}\")\n",
        "    print(f\"processed_docs[0]: {processed_docs[0]}\")\n",
        "    _ = vector_store.add_documents(documents=processed_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42c26d5f-1493-4ad6-9210-ea2723695149",
      "metadata": {
        "id": "42c26d5f-1493-4ad6-9210-ea2723695149"
      },
      "source": [
        "### Retrival and Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29b2e525",
      "metadata": {},
      "source": [
        "Make a graph to chain our model operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "e27d97f0-27dc-438b-bf61-a403ca284522",
      "metadata": {
        "id": "e27d97f0-27dc-438b-bf61-a403ca284522"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import MessagesState, StateGraph\n",
        "\n",
        "graph_builder = StateGraph(MessagesState)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35eeb6a1-29f2-4086-8b6f-8761cf24ce59",
      "metadata": {
        "id": "35eeb6a1-29f2-4086-8b6f-8761cf24ce59"
      },
      "source": [
        "Define functions for tool calling, which helps the model to preprocess user raw input and decide whether need to run the retrival step or not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "8201a6ef-942f-4571-b3b9-55a430590266",
      "metadata": {
        "id": "8201a6ef-942f-4571-b3b9-55a430590266"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import SystemMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from qdrant_client import models\n",
        "\n",
        "def extract_search_parameters(query: str):\n",
        "    \"\"\"Use LLM to extract search parameters from a user query.\"\"\"\n",
        "    \n",
        "    system_message = \"\"\"You are an intelligent assistant that extracts company names from user queries.\n",
        "    Your task is to identify any company names mentioned in the user query.\n",
        "    You MUST return ONLY the company names as a comma-separated string.\n",
        "    If no company is found, return None.\n",
        "    You MUST return the response in the exact format specified, and without any extra information.\n",
        "    \n",
        "    Example:\n",
        "    Query: \"Which Georgia Tech alumni work at Google?\"\n",
        "    Response: \"Google\"\n",
        "    \n",
        "    Query: \"Find alumni who work at Microsoft or Amazon\"\n",
        "    Response: \"Microsoft,Amazon\"\n",
        "    \n",
        "    Query: \"Show me alumni who studied Computer Science\"\n",
        "    Response: \"None\"\n",
        "    \"\"\"\n",
        "    \n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", system_message),\n",
        "        (\"human\", \"Extract search parameters from the following query: {query}\")\n",
        "    ])\n",
        "    \n",
        "    # Get structured output from LLM\n",
        "    response = llm.invoke(prompt.format_messages(query=query))\n",
        "    \n",
        "    # Parse the response\n",
        "    companies = response.content.strip()\n",
        "    if companies == \"None\":\n",
        "        return None\n",
        "    \n",
        "    # Split and clean the companies\n",
        "    companies = [c.strip() for c in companies.split(\",\")]\n",
        "    return companies\n",
        "\n",
        "\n",
        "@tool(response_format=\"content_and_artifact\")\n",
        "def retrieve(query: str):\n",
        "    \"\"\"Retrieve information related to a query.\"\"\"\n",
        "    \n",
        "    # Extract companies from the query\n",
        "    companies = extract_search_parameters(query)\n",
        "    print(f\"company name generated from query: {companies}\")\n",
        "\t# Create a filter that checks if any company in the document's metadata\n",
        "    # matches any of the queried companies\n",
        "    if companies:\n",
        "        filter_conditions = models.Filter(\n",
        "\t\t\tshould=[\n",
        "\t\t\t\tmodels.FieldCondition(\n",
        "\t\t\t\t\tkey=\"metadata.companies\",\n",
        "\t\t\t\t\tmatch=models.MatchAny(any=companies)\n",
        "\t\t\t\t),\n",
        "\t\t\t]\n",
        "\t\t)\n",
        "    else:\n",
        "        filter_conditions = None\n",
        "    \n",
        "    retrieved_docs = vector_store.similarity_search(query, k=2, filter=filter_conditions)\n",
        "    \n",
        "    serialized = \"\\n\".join(\n",
        "        f\"{idx+1}: {doc.page_content}\"\n",
        "        for idx, doc in enumerate(retrieved_docs)\n",
        "    )\n",
        "    return serialized, retrieved_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b03f752-d46d-4070-b790-197b742c4dc2",
      "metadata": {
        "id": "9b03f752-d46d-4070-b790-197b742c4dc2"
      },
      "source": [
        "Define step functions for the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "4d0ce8c9-b404-424b-886e-c1386368ec24",
      "metadata": {
        "id": "4d0ce8c9-b404-424b-886e-c1386368ec24"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "\n",
        "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
        "def query_or_respond(state: MessagesState):\n",
        "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
        "    system_message = SystemMessage(\n",
        "        \"You are a specialized assistant for Georgia Tech students seeking information about GT alumni. \"\n",
        "        \"Instructions for tool usage:\"\n",
        "        \"\\n1. USE the retrieve tool ONLY when searching for specific alumni information (names, careers, experiences, etc.).\"\n",
        "        \"\\n2. DO NOT use the retrieve tool for general queries, greetings, or when you already have sufficient information.\"\n",
        "        \"\\n3. Respond naturally without mentioning your tool usage decisions to the user.\"\n",
        "    )\n",
        "    messages = [system_message] + state[\"messages\"]\n",
        "    llm_with_tools = llm.bind_tools([retrieve]) # Only tells the model there's an available tool to use. The model will decide whether to use it depending on the input message\n",
        "    response = llm_with_tools.invoke(messages)\n",
        "    # MessagesState appends messages to state instead of overwriting\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "\n",
        "# Step 2: Execute the retrieval.\n",
        "tools = ToolNode([retrieve])\n",
        "\n",
        "\n",
        "# Step 3: Generate a response using the retrieved content.\n",
        "def generate(state: MessagesState):\n",
        "    \"\"\"Generate answer.\"\"\"\n",
        "    # Get generated ToolMessages\n",
        "    recent_tool_messages = []\n",
        "    for message in reversed(state[\"messages\"]):\n",
        "        if message.type == \"tool\":\n",
        "            recent_tool_messages.append(message)\n",
        "        else:\n",
        "            break\n",
        "    tool_messages = recent_tool_messages[::-1]\n",
        "\n",
        "    # Format into prompt\n",
        "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
        "    \n",
        "   \n",
        "\n",
        "    conversation_messages = [\n",
        "        message\n",
        "        for message in state[\"messages\"]\n",
        "        if message.type in (\"human\", \"system\")\n",
        "        or (message.type == \"ai\" and not message.tool_calls)\n",
        "    ]\n",
        "    \n",
        "    # Create a static system message for instructing behavior.\n",
        "    system_message = SystemMessage(\n",
        "        \"You are an assistant for helping Georgia Tech college students find Georgia Tech alumni. \"\n",
        "        \"You are given a question and a list of retrieved JSON documents about Georgia Tech alumni. \"\n",
        "        \"ONLY use the facts from the provided DOCUMENT to answer the question. \"\n",
        "        \"Do not incorporate any external or pre-existing knowledge. \"\n",
        "        \"If the DOCUMENT does not contain sufficient information to answer the question, return {NONE}.\"\n",
        "    )\n",
        "    \n",
        "    human_message_content = f\"\"\"DOCUMENT:\n",
        "        {docs_content}\n",
        "\n",
        "        QUESTION:\n",
        "        {conversation_messages[-1].content}\n",
        "\n",
        "        INSTRUCTIONS:\n",
        "        Answer the user's QUESTION using ONLY the facts provided in the DOCUMENT above.\n",
        "        Do not include any information not present in the DOCUMENT.\n",
        "        If the DOCUMENT does not contain the facts needed to answer the question, return {{NONE}}.\n",
        "        You MUST return your answer in the following JSON format containing the alumni's name, linkedin id, and summary of their experience using the information from the DOCUMENT.\n",
        "        \"\"\"\n",
        "\n",
        "    human_message = HumanMessage(human_message_content)\n",
        "\n",
        "    prompt = [system_message, human_message]\n",
        " \n",
        "    # Run\n",
        "    response = llm.invoke(prompt)\n",
        "\n",
        "    \n",
        "    # print(\"=== DEBUG PROMPT ===\")\n",
        "    # for msg in prompt:\n",
        "    #     print(f\"Type: {msg.type}\")\n",
        "    #     print(f\"Content: {msg.content}\")\n",
        "    #     print(\"---\")\n",
        "\n",
        "    # print(\"=== DEBUG RESPONSE ===\")\n",
        "    # print(f\"Type: {response.type}\")\n",
        "    # print(f\"Content: {response.content}\")\n",
        "    # print(\"===================\")\n",
        "\n",
        "\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "\n",
        " # system_message_content = f\"\"\"You are an assistant for helping Georgia Tech college students find Georgia Tech alumni. \n",
        "    # You are given a question and a list of retrieved JSON documents about Georgia Tech alumni.\n",
        "\n",
        "    # RULES:\n",
        "    # 1. Only reference information from the retrieved documents\n",
        "    # 2. Response MUST be in this JSON format: [{{'id': 'linkedin_url', 'name': 'full_name', 'summary': 'experience_summary'}}]\n",
        "    # 3. If no matching alumni are found in the retrieved documents, return an empty array: []\n",
        "\n",
        "    # FAILURE TO FOLLOW THESE RULES will result in incorrect output.\n",
        "\n",
        "    # EXAMPLE:\n",
        "    # Question: Who is working at Google?\n",
        "\n",
        "    # Retrieved information:\n",
        "    # {{\n",
        "    #     'Id': 'www.example.com',\n",
        "    #     'Name': 'John Doe',\n",
        "    #     'About': 'A SWE intern at Google',\n",
        "    #     'Headline': 'BSCS @ Georgia Tech | SWE intern @ Google',\n",
        "    #     'Location': 'Mountain View, CA',\n",
        "    #     'Profile_Pic': 'linkedin_url',\n",
        "    #     'Experiences': [\n",
        "    #         {{\n",
        "    #             'Title': 'SWE intern',\n",
        "    #             'Company': 'Google',\n",
        "    #             'Location': 'Mountain View, CA',\n",
        "    #             'Description': 'A SWE intern at Google',\n",
        "    #             'Duration': {{\n",
        "    #                 'Start': '2025-05-01',\n",
        "    #                 'End': '2024-08-01'\n",
        "    #             }}\n",
        "    #         }}\n",
        "    #     ],\n",
        "    #     'Education': [\n",
        "    #         {{\n",
        "    #             'School': 'Georgia Institute of Technology',\n",
        "    #             'Degree': 'BSCS',\n",
        "    #             'Major': 'Computer Science',\n",
        "    #             'Description': 'A BSCS senior',\n",
        "    #             'Duration': {{\n",
        "    #                 'Start': '2020-08-01',\n",
        "    #                 'End': '2024-05-01'\n",
        "    #             }}\n",
        "    #         }}\n",
        "    #     ]\n",
        "    # }}\n",
        "\n",
        "    # Answer: [{{'id': 'www.example.com', 'name': 'John Doe', 'summary': 'John Doe is an incoming 2025 summer software engineer intern at Google'}}]\n",
        "\n",
        "    # Retrieved information:\n",
        "    # {docs_content}\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b409ee5f-2973-47ee-a1bf-112731843c5d",
      "metadata": {
        "id": "b409ee5f-2973-47ee-a1bf-112731843c5d"
      },
      "source": [
        "Finally, we compile our application into a single `graph` object. In this case, we are just connecting the steps into a sequence. We also allow the first `query_or_respond` step to \"short-circuit\" and respond directly to the user if it does not generate a tool call. This allows our application to support conversational experiences-- e.g., responding to generic greetings that may not require a retrieval step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "ac33f19c-7959-4526-8f12-0de76ae10387",
      "metadata": {
        "id": "ac33f19c-7959-4526-8f12-0de76ae10387"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import END\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "graph_builder.add_node(query_or_respond)\n",
        "graph_builder.add_node(tools)\n",
        "graph_builder.add_node(generate)\n",
        "\n",
        "graph_builder.set_entry_point(\"query_or_respond\")\n",
        "graph_builder.add_conditional_edges(\n",
        "    \"query_or_respond\",\n",
        "    tools_condition,\n",
        "    {END: END, \"tools\": \"tools\"},\n",
        ")\n",
        "graph_builder.add_edge(\"tools\", \"generate\")\n",
        "graph_builder.add_edge(\"generate\", END)\n",
        "\n",
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "5c7e1717-d262-4947-a64d-6b116e53856a",
      "metadata": {
        "id": "5c7e1717-d262-4947-a64d-6b116e53856a",
        "outputId": "62e0053c-9e37-4815-ac2e-cc0dfc125f67"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "236b6209-ee06-42ba-b266-d90d9cbf224b",
      "metadata": {
        "id": "236b6209-ee06-42ba-b266-d90d9cbf224b"
      },
      "source": [
        "## Testing\n",
        "\n",
        "Note that it responds appropriately to messages that do not require an additional retrieval step:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fbca953-970d-4271-be30-6c7799893dd1",
      "metadata": {
        "id": "4fbca953-970d-4271-be30-6c7799893dd1",
        "outputId": "31d6fe54-5084-428b-c380-b3609df9b126"
      },
      "outputs": [],
      "source": [
        "input_message = \"Hello. I'm Yihao. How are you?\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5df5046d-4610-4ffa-9f30-d04453da05a9",
      "metadata": {
        "id": "5df5046d-4610-4ffa-9f30-d04453da05a9"
      },
      "source": [
        "And when executing a search, we can stream the steps to observe the query generation, retrieval, and answer generation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "9ab78984-d7fa-40e1-a440-c041a6456c1f",
      "metadata": {
        "id": "9ab78984-d7fa-40e1-a440-c041a6456c1f",
        "outputId": "da0f5594-22c7-4aa1-fb0a-c2e998dea95b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Which Georgia Tech Alumni are working at Google?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (256a0a7b-7183-4cfe-b6a5-aa807bcd41a6)\n",
            " Call ID: 256a0a7b-7183-4cfe-b6a5-aa807bcd41a6\n",
            "  Args:\n",
            "    query: Georgia Tech alumni working at Google\n",
            "company name generated from query: ['Google']\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "1: {\"Id\": \"https://www.linkedin.com/in/roserwen/\", \"Profile_Pic\": \"https://media.licdn.com/dms/image/v2/D4E03AQHdsMga0b_Juw/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1718241851575?e=1749081600&v=beta&t=G8SQ7r4CDgqG4tXZ4A8NdUCgx73J993v6hMYEy6XZUc\", \"Name\": \"Rose Wen\", \"About\": null, \"Headline\": \"Incoming SWE Intern @ Google | CS @ Georgia Tech\", \"Location\": \"Atlanta, Georgia, United States\", \"Experiences\": [{\"Title\": \"STEP Intern\", \"Company\": \"Google\", \"Work_Type\": \"Internship\", \"Location\": \"Cambridge, Massachusetts, United States \\u00b7 Hybrid\", \"Description\": \"Google Travel\", \"Duration\": {\"Start\": \"May 2023\", \"End\": \"Aug 2023\"}}, {\"Title\": \"STEP Intern\", \"Company\": \"Google\", \"Work_Type\": \"Internship\", \"Location\": \"Kirkland, Washington, United States \\u00b7 Hybrid\", \"Description\": \"Connections Android\", \"Duration\": {\"Start\": \"May 2024\", \"End\": \"Aug 2024\"}}], \"Education\": [{\"School\": \"Georgia Institute of Technology\", \"Degree\": \"Bachelor of Science - BS\", \"Major\": \"Computer Science\", \"Description\": \"\", \"Duration\": {\"Start\": \"2022\", \"End\": \"2025\"}}]}\n",
            "2: {\"Id\": \"https://www.linkedin.com/in/anh-thai/\", \"Profile_Pic\": \"https://media.licdn.com/dms/image/v2/D4E03AQE1Uzxi2dkVFQ/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1728028939471?e=1749081600&v=beta&t=CWjYfBF6PXPZXlNo7_gNJgv7AGuIXlD72j4lBfvFMhM\", \"Name\": \"Anh N. Thai\", \"About\": \"I am a PhD student in Computer Science at Georgia Institute of Technology, advised by Professor James M. Rehg and Professor Judy Hoffman. My research interests lie in the fields of Computer Vision and Deep Learning.\\nMy personal website: https://anhthai1997.wordpress.com/\", \"Headline\": \"PhD Student at Georgia Institute of Technology\", \"Location\": \"Atlanta, Georgia, United States\", \"Experiences\": [{\"Title\": \"Senior AI Multimodal Researcher\", \"Company\": \"Dolby Laboratories\", \"Work_Type\": \"Full-time\", \"Location\": \"Atlanta, Georgia, United States \\u00b7 Hybrid\", \"Description\": \"\", \"Duration\": {\"Start\": \"Feb 2025\", \"End\": null}}, {\"Title\": \"Graduate Teaching Assistant\", \"Company\": \"Georgia Institute of Technology\", \"Work_Type\": null, \"Location\": \"Atlanta, Georgia, United States\", \"Description\": \"Teaching assistant for CS 6476: Computer Vision Graduate Teaching Assistant\", \"Duration\": {\"Start\": \"Aug 2024\", \"End\": \"Dec 2024\"}}, {\"Title\": \"Graduate Research Assistant\", \"Company\": \"Georgia Institute of Technology\", \"Work_Type\": null, \"Location\": null, \"Description\": \"Current research generally focuses on computer vision problems inspired by developmental psychology\\n- Investigating the properties of self-supervised visual representation learning under scenarios that closely resemble infant learning\\n- Understanding the relationship between 3D object shapes and categorization in few-shot and continual learning settings\", \"Duration\": {\"Start\": \"Aug 2019\", \"End\": \"Dec 2024\"}}, {\"Title\": \"Graduate Teaching Assistant\", \"Company\": \"Georgia Institute of Technology\", \"Work_Type\": null, \"Location\": \"Atlanta, Georgia, United States\", \"Description\": \"Teaching assistant for CS 7647: Machine Learning with Limited Supervision Graduate Teaching Assistant\", \"Duration\": {\"Start\": \"Aug 2023\", \"End\": \"Dec 2023\"}}, {\"Title\": \"Graduate Teaching Assistant\", \"Company\": \"Georgia Institute of Technology\", \"Work_Type\": null, \"Location\": null, \"Description\": \"Teaching assistant for CS 7626: Behavioral Imaging Graduate Teaching Assistant\", \"Duration\": {\"Start\": \"Jan 2022\", \"End\": \"May 2022\"}}, {\"Title\": \"Undergraduate Research Assistant\", \"Company\": \"Georgia Institute of Technology\", \"Work_Type\": null, \"Location\": null, \"Description\": \"- Research focused on computer vision and deep learning, advised by Dr. James Rehg.\\n- Co-second author on \\\"Incremental Object Learning from Contiguous Views\\\" (CVPR 2019 - Oral, Best paper finalists).\\n- Investigated domain shift issue in transfer learning from synthetic to real data.\", \"Duration\": {\"Start\": \"Aug 2017\", \"End\": \"Aug 2019\"}}, {\"Title\": \"Student Researcher\", \"Company\": \"Google DeepMind\", \"Work_Type\": \"Internship\", \"Location\": \"Mountain View, California, United States \\u00b7 On-site\", \"Description\": \"3D scene understanding\", \"Duration\": {\"Start\": \"May 2024\", \"End\": \"Nov 2024\"}}, {\"Title\": \"Student Researcher\", \"Company\": \"Meta\", \"Work_Type\": null, \"Location\": \"Remote\", \"Description\": \"3D object understanding research at FAIR\", \"Duration\": {\"Start\": \"Aug 2023\", \"End\": \"Dec 2023\"}}, {\"Title\": \"Research Scientist Intern\", \"Company\": \"Meta\", \"Work_Type\": null, \"Location\": \"On-site\", \"Description\": \"3D object understanding research at FAIR\", \"Duration\": {\"Start\": \"May 2023\", \"End\": \"Aug 2023\"}}, {\"Title\": \"Research Intern\", \"Company\": \"Meta\", \"Work_Type\": \"Internship\", \"Location\": \"Redmond, Washington, United States\", \"Description\": \"- Investigated incremental learning of object 3D representations\\n- Used PyTorch, OpenCV and NumPy\", \"Duration\": {\"Start\": \"May 2021\", \"End\": \"Aug 2021\"}}, {\"Title\": \"Software Engineering Intern\", \"Company\": \"Google\", \"Work_Type\": null, \"Location\": \"Mountain View, California\", \"Description\": \"- Improved human label quality and implemented the end-to-end training pipeline for large-scale YouTube video classification task\\n- Used SQL, C++, Python, TensorFlow, and Colab\", \"Duration\": {\"Start\": \"May 2018\", \"End\": \"Aug 2018\"}}, {\"Title\": \"Software Engineering Intern\", \"Company\": \"Google\", \"Work_Type\": null, \"Location\": \"Venice, California\", \"Description\": \"- Implemented the client code of the in-app notification screen of Google Ads app in Flutter framework\", \"Duration\": {\"Start\": \"May 2017\", \"End\": \"Aug 2017\"}}, {\"Title\": \"Undergraduate Teaching Assistant\", \"Company\": \"Georgia Institute of Technology\", \"Work_Type\": null, \"Location\": null, \"Description\": \"- Teaching assistant for CS 2340: Objects and Design.\\n- In charge of 5 teams (5 people/team), graded homework, demoes and exams, held office hours every week, helped students with software engineering concepts.\", \"Duration\": {\"Start\": \"Jan 2017\", \"End\": \"May 2017\"}}, {\"Title\": \"Undergraduate Teaching Assistant\", \"Company\": \"Georgia Institute of Technology\", \"Work_Type\": null, \"Location\": \"Greater Atlanta Area\", \"Description\": \"- Teaching assistant for Math 1553: Intro to Linear Algebra.\\n- Taught recitations, proctored, graded quizzes and exams (about 100 paper each time), held office hours every week, in charge of approximately 70 students.\", \"Duration\": {\"Start\": \"Aug 2016\", \"End\": \"Dec 2016\"}}], \"Education\": [{\"School\": \"Georgia Institute of Technology\", \"Degree\": \"Doctor of Philosophy - PhD\", \"Major\": \"Computer Science\", \"Description\": \"Grade: 4.0/4.0\", \"Duration\": {\"Start\": \"2019\", \"End\": \"2024\"}}, {\"School\": \"Georgia Institute of Technology\", \"Degree\": \"Master of Science - MS\", \"Major\": \"Computer Science\", \"Description\": \"Grade: 4.0/4.0\", \"Duration\": {\"Start\": \"May 2024\", \"End\": \"May 2024\"}}, {\"School\": \"Georgia Institute of Technology\", \"Degree\": \"Bachelor's degree\", \"Major\": \"Computer Science\", \"Description\": \"Grade: Overall GPA: 3.94/4.0\", \"Duration\": {\"Start\": \"2015\", \"End\": \"2019\"}}, {\"School\": \"Le Quy Don High School for The Gifted\", \"Degree\": \"High School Diploma\", \"Major\": \"Mathematics\", \"Description\": \"Grade: 9.3/10\", \"Duration\": {\"Start\": \"2012\", \"End\": \"2015\"}}]}\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Here is the answer:\n",
            "\n",
            "```\n",
            "{\n",
            "  \"Anurag Mehta\": {\n",
            "    \"linkedin_id\": \"https://www.linkedin.com/in/anurag-mehta-7a4b8a11/\",\n",
            "    \"summary\": \"Software Engineering Intern at Google\"\n",
            "  },\n",
            "  \"Unknown Alumni\": {\n",
            "    \"linkedin_id\": \"https://www.linkedin.com/in/unknown-alumni/\", // We don't have the actual linkedin id\n",
            "    \"summary\": \"Working at Google\"\n",
            "  }\n",
            "}\n",
            "```\n",
            "\n",
            "However, since we only have one alumni working at Google and their name is not Anurag Mehta (we cannot be certain who it is because there are multiple people with the company Google), I will just return one record.\n",
            "\n",
            "Here is the JSON:\n",
            "\n",
            "```\n",
            "{\n",
            "  \"Anurag Mehta\": {\n",
            "    \"linkedin_id\": \"https://www.linkedin.com/in/anurag-mehta-7a4b8a11/\",\n",
            "    \"summary\": \"Software Engineering Intern at Google\"\n",
            "  }\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "input_message = \"Which Georgia Tech Alumni are working at Google?\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "88a4f0e3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Who works at Capital One?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (8712b10b-206f-4a7c-ad07-ee6cbedbffe2)\n",
            " Call ID: 8712b10b-206f-4a7c-ad07-ee6cbedbffe2\n",
            "  Args:\n",
            "    query: Capital One\n",
            "company name generated from query: ['Capital One']\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "1: {\"Id\": \"https://www.linkedin.com/in/rhea-jaxon/\", \"Profile_Pic\": \"https://media.licdn.com/dms/image/v2/D5603AQFeKjwrTYtQgw/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1696370046180?e=1749081600&v=beta&t=4YRc4d7ZkizysemFkJa1dFwUNpqmYjsp3te2InnmfOQ\", \"Name\": \"Rhea Jaxon\", \"About\": \"I am a computer scientist with a passion for immersing myself in diverse experiences, whether through internships in various disciplines, collaborating with different teams, or exploring applications across industries. My strong technical skills, including proficiency in Java, C, Python, and HTML, are complemented by an academic background in engineering and statistics. I love public speaking and networking, so please do not hesitate to connect with me and follow me on my journey in my aspirations. Currently, I am focused on product management and actively seeking opportunities to gain expertise and excel in this field.\\n\\nGitHub link: https://github.com/rjaxon3/PastProjects\", \"Headline\": \"CS @ Georgia Institute of Technology | Denning Technology & Management Scholar | IBM Ambassador\", \"Location\": \"Littleton, Colorado, United States\", \"Experiences\": [{\"Title\": \"User Experience Designer\", \"Company\": \"Georgia Institute of Technology\", \"Work_Type\": \"Part-time\", \"Location\": \"On-site\", \"Description\": \"Creating user accounts for computing resource allocation for groups in Georgia Tech Research Institution\\nWorking in a Linux environment for working with high parallel computing and documentation of IT resources for tech support\", \"Duration\": {\"Start\": \"Feb 2024\", \"End\": \"Present\"}}, {\"Title\": \"ServiceNow Developer\", \"Company\": \"Wellstar Health System\", \"Work_Type\": \"Part-time\", \"Location\": \"Georgia, United States\", \"Description\": \"Supported the IT team in managing incidents and problems within ServiceNow, ensuring timely resolution and minimizing service disruptions.\\nAssisted in routine maintenance and upgrades of the ServiceNow platform, ensuring continuous availability and optimal performance.\\nContributed to the development of custom ServiceNow applications to meet specific business needs, increasing the platform's versatility.\", \"Duration\": {\"Start\": \"Aug 2024\", \"End\": \"Dec 2024\"}}, {\"Title\": \"Section Leader for CS105\", \"Company\": \"Stanford University\", \"Work_Type\": \"Contract\", \"Location\": \"Remote \\u00b7 Remote\", \"Description\": \"Designing and delivering comprehensive tutorials on Python programming, HTML structure, and CSS styling, breaking down complex concepts into digestible segments for students to grasp effectively.\\nDeveloping and teaching hands-on coding exercises and interactive examples which demonstrated practical applications of Python and HTML encouraging students to apply gained knowledge in real-world scenarios.\\nMentoring with other section leaders to efficiently teach coding intensive courses in a span of 15 weeks.\", \"Duration\": {\"Start\": \"Aug 2023\", \"End\": \"Dec 2024\"}}, {\"Title\": \"Global Technology Analyst\", \"Company\": \"Bank of America\", \"Work_Type\": \"Internship\", \"Location\": \"Charlotte, North Carolina, United States \\u00b7 Hybrid\", \"Description\": \"\", \"Duration\": {\"Start\": \"Jun 2024\", \"End\": \"Aug 2024\"}}, {\"Title\": \"AT&T Technology Academy Extern\", \"Company\": \"AT&T\", \"Work_Type\": \"Internship\", \"Location\": \"\", \"Description\": \"Developed expertise in network technologies, cybersecurity, cloud computing, and software development through hands-on labs and workshops.\\nCollaborated with AT&T subject matter experts to gain insights into industry trends and best practices.\\nEnhanced skills in practical application of theoretical knowledge through real-world projects and simulations.\", \"Duration\": {\"Start\": \"Jun 2024\", \"End\": \"Jul 2024\"}}, {\"Title\": \"Extern BA Minimester\", \"Company\": \"Capital One\", \"Work_Type\": \"Seasonal\", \"Location\": \"\", \"Description\": \"Developed critical thinking and problem-solving skills through business casing exercises, preparing me for real-world challenges in a corporate environment.\\nExplored career pathways at Capital One through informative sessions covering internship and full-time roles, understanding the company's culture and expectations.\\nExpanded my professional network through structured networking opportunities, connecting with peers, mentors, and industry professionals.\\nDelved into data pathways, understanding the role of data in driving business decisions and enhancing analytical capabilities.\", \"Duration\": {\"Start\": \"Jun 2024\", \"End\": \"Jun 2024\"}}, {\"Title\": \"Extern\", \"Company\": \"igniteXL Ventures\", \"Work_Type\": \"Internship\", \"Location\": \"Remote\", \"Description\": \"Gained a comprehensive understanding of VC deal sourcing fundamentals and investment thesis development\\nConducted in-depth research using platforms like Crunchbase and the internet to gather data and insights\\nPracticed variable estimation techniques such as market sizing and revenue projection\\nUtilized AI tools like ChatGPT and Bard for research purposes and prompt engineering\\nCreated a concise and impactful investment summary incorporating research insights and recommendations.\", \"Duration\": {\"Start\": \"Sep 2023\", \"End\": \"Oct 2023\"}}, {\"Title\": \"Research And Development Intern\", \"Company\": \"Hyperledger Foundation\", \"Work_Type\": \"Seasonal\", \"Location\": \"Remote \\u00b7 Remote\", \"Description\": \"Developed chain code and created a basic data model with privacy considerations (using PDC).\\nCoded an extension to support the use of HFL as data storage with privacy and resilience guarantees.\\nCreated documentation to help potential (mostly industry-oriented) user community evaluate blockchain solutions.\", \"Duration\": {\"Start\": \"Aug 2023\", \"End\": \"Sep 2023\"}}, {\"Title\": \"Apprentice\", \"Company\": \"The Linux Foundation\", \"Work_Type\": \"Internship\", \"Location\": \"Remote\", \"Description\": \"Collaborated with software engineers to program, modify, and update open-source project code in different languages.\\nEmployed and adapted to new operating systems and open-source tools Communicated in a team-building environment to manage deadlines.\", \"Duration\": {\"Start\": \"May 2023\", \"End\": \"Jul 2023\"}}, {\"Title\": \"Board of Nonprofit Partnerships\", \"Company\": \"Bits of Good\", \"Work_Type\": \"Part-time\", \"Location\": \"Atlanta Metropolitan Area \\u00b7 On-site\", \"Description\": \"Coordinated with nonprofits to help design or rebuild software for nonprofit organizations\\nManaged and wrote proposals for build assignments in software development in websites\\nDeveloped compelling and strategic pitch presentations for a variety of software development projects, effectively communicating complex technical concepts to diverse stakeholders, including clients, executives, and cross-functional teams.\", \"Duration\": {\"Start\": \"Dec 2022\", \"End\": \"May 2023\"}}, {\"Title\": \"CSBR Ambassador\", \"Company\": \"Colorado Space Business Roundtable\", \"Work_Type\": \"Internship\", \"Location\": \"Colorado, United States\", \"Description\": \"Worked and shadowed with local aerospace companies such as Lockheed Martin\\nInternet and interviewed aerospace engineers in the field\\nResearched about implementing an algorithm to maximize individual productivity\\nPresented findings at annual CSBR event to an international presence.\", \"Duration\": {\"Start\": \"Jul 2020\", \"End\": \"Dec 2022\"}}, {\"Title\": \"Research Assistant\", \"Company\": \"Deep Space Predictive Research Group (DSPRG)\", \"Work_Type\": \"Contract\", \"Location\": \"United States \\u00b7 Hybrid\", \"Description\": \"Monitored heart rate variability amongst individuals to test compatibility\\nAnalyzed vagal tones to organize data\\nProcessed information for app/software development for NASA HERO proposal.\", \"Duration\": {\"Start\": \"Jun 2021\", \"End\": \"Apr 2022\"}}, {\"Title\": \"Intern\", \"Company\": \"Air Academy Federal Credit Union\", \"Work_Type\": \"Internship\", \"Location\": \"Highlands Ranch, Colorado, United States\", \"Description\": \"Worked with and learned about the latest banking technology and software with DNA\\nShadowed the IT to gain knowledge on troubleshooting\\nInformed consumers of financial options with financial literacy.\", \"Duration\": {\"Start\": \"May 2021\", \"End\": \"Apr 2022\"}}, {\"Title\": \"Tutor\", \"Company\": \"Eye Level Learning\", \"Work_Type\": \"Part-time\", \"Location\": \"Highlands Ranch, Colorado, United States\", \"Description\": \"Tutoring young students as well as contributing to organizational/inventory duties.\", \"Duration\": {\"Start\": \"Aug 2019\", \"End\": \"Mar 2020\"}}], \"Education\": [{\"School\": \"Georgia Institute of Technology\", \"Degree\": \"Bachelor of Science - BS\", \"Major\": \"Computer Science\", \"Description\": \"Activities and societies: Executive Vice President of Multicultural Panhellenic Council\\nSigma Sigma Rho Sorority Inc, Data Science Club, Society of Women in Engineering, Student Alumni Association\", \"Duration\": {\"Start\": \"Jun 2022\", \"End\": \"May 2026\"}}, {\"School\": \"Rock Canyon High School\", \"Degree\": \"High School Diploma\", \"Major\": \"Computer Science\", \"Description\": \"\", \"Duration\": {\"Start\": \"2018\", \"End\": \"2022\"}}]}\n",
            "2: {\"Id\": \"https://www.linkedin.com/in/anthony-sungjin-hong/\", \"Profile_Pic\": \"https://media.licdn.com/dms/image/v2/D5603AQEkMakBmNKPuQ/profile-displayphoto-shrink_800_800/profile-displayphoto-shrink_800_800/0/1696619145214?e=1749081600&v=beta&t=nEioKHkjuHcev4AlpPla6eEnBrw7SZC4FL-bvjwR2yw\", \"Name\": \"Anthony Hong\", \"About\": null, \"Headline\": \"SWE Intern @ Databricks | CS @ Georgia Tech\", \"Location\": \"Atlanta, Georgia, United States\", \"Experiences\": [{\"Title\": \"Software Engineer Intern\", \"Company\": \"Databricks\", \"Work_Type\": \"Internship\", \"Location\": \"San Francisco, California, United States\", \"Description\": \"\", \"Duration\": {\"Start\": \"May 2024\", \"End\": \"Aug 2024\"}}, {\"Title\": \"Software Engineer Intern\", \"Company\": \"Capital One\", \"Work_Type\": \"Internship\", \"Location\": \"Plano, Texas, United States\", \"Description\": \"\", \"Duration\": {\"Start\": \"Jun 2023\", \"End\": \"Aug 2023\"}}, {\"Title\": \"Research Intern\", \"Company\": \"Georgia Tech Research Institute\", \"Work_Type\": \"Internship\", \"Location\": \"Atlanta, Georgia, United States\", \"Description\": \"\", \"Duration\": {\"Start\": \"May 2022\", \"End\": \"Jul 2022\"}}], \"Education\": [{\"School\": \"Georgia Institute of Technology\", \"Degree\": \"Bachelor of Science - BS\", \"Major\": \"Computer Science\", \"Description\": \"Grade: 4.0/4.0\", \"Duration\": {\"Start\": \"Aug 2021\", \"End\": \"Dec 2024\"}}]}\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "After analyzing the provided document, I found that there are multiple individuals who have worked at Capital One. Here is the answer for each one:\n",
            "\n",
            "1. **Anthony Hong**\n",
            "   - Name: Anthony Hong\n",
            "   - LinkedIn ID: https://www.linkedin.com/in/anthony-sungjin-hong/\n",
            "   - Experience Summary: Held a Software Engineer Intern position at Capital One from Jun 2023 to Aug 2023.\n",
            "\n",
            "2. **Anthony Sungjin Hong** (Second Document)\n",
            "   - Name: Anthony Sungjin Hong\n",
            "   - LinkedIn ID: https://www.linkedin.com/in/anthony-sungjin-hong/\n",
            "   - Experience Summary: Held a Software Engineer Intern position at Capital One from Jun 2023 to Aug 2023.\n",
            "\n",
            "Since there are multiple individuals with the same last name, I provided the answer for both of them. If you want to get the information for only one person, please let me know and I can provide it to you.\n",
            "\n",
            "The JSON format for each answer is as follows:\n",
            "\n",
            "```\n",
            "{\n",
            "    \"Name\": \"Anthony Hong\",\n",
            "    \"LinkedIn ID\": \"https://www.linkedin.com/in/anthony-sungjin-hong/\",\n",
            "    \"Experience Summary\": \"Held a Software Engineer Intern position at Capital One from Jun 2023 to Aug 2023.\"\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "input_message = \"Who works at Capital One?\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a26a9c4d-0e5b-4db9-8b78-68624d829ac2",
      "metadata": {
        "id": "a26a9c4d-0e5b-4db9-8b78-68624d829ac2"
      },
      "source": [
        "Check out the LangSmith trace [here](https://smith.langchain.com/public/70110399-01d3-4b4b-9139-cbcd4edf9d6d/r)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d9d16f8",
      "metadata": {},
      "source": [
        "# I haven't modified below code for our model, just skip them"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2300c04-019c-4c65-a104-3dbf17c924b7",
      "metadata": {
        "id": "c2300c04-019c-4c65-a104-3dbf17c924b7"
      },
      "source": [
        "### Stateful management of chat history\n",
        "\n",
        ":::note\n",
        "\n",
        "This section of the tutorial previously used the [RunnableWithMessageHistory](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html) abstraction. You can access that version of the documentation in the [v0.2 docs](https://python.langchain.com/v0.2/docs/tutorials/chatbot/).\n",
        "\n",
        "As of the v0.3 release of LangChain, we recommend that LangChain users take advantage of [LangGraph persistence](https://langchain-ai.github.io/langgraph/concepts/persistence/) to incorporate `memory` into new LangChain applications.\n",
        "\n",
        "If your code is already relying on `RunnableWithMessageHistory` or `BaseChatMessageHistory`, you do **not** need to make any changes. We do not plan on deprecating this functionality in the near future as it works for simple chat applications and any code that uses `RunnableWithMessageHistory` will continue to work as expected.\n",
        "\n",
        "Please see [How to migrate to LangGraph Memory](/docs/versions/migrating_memory/) for more details.\n",
        ":::\n",
        "\n",
        "In production, the Q&A application will usually persist the chat history into a database, and be able to read and update it appropriately.\n",
        "\n",
        "[LangGraph](https://langchain-ai.github.io/langgraph/) implements a built-in [persistence layer](https://langchain-ai.github.io/langgraph/concepts/persistence/), making it ideal for chat applications that support multiple conversational turns.\n",
        "\n",
        "To manage multiple conversational turns and threads, all we have to do is specify a [checkpointer](https://langchain-ai.github.io/langgraph/concepts/persistence/) when compiling our application. Because the nodes in our graph are appending messages to the state, we will retain a consistent chat history across invocations.\n",
        "\n",
        "LangGraph comes with a simple in-memory checkpointer, which we use below. See its [documentation](https://langchain-ai.github.io/langgraph/concepts/persistence/) for more detail, including how to use different persistence backends (e.g., SQLite or Postgres).\n",
        "\n",
        "For a detailed walkthrough of how to manage message history, head to the [How to add message history (memory)](/docs/how_to/message_history) guide."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "e5cd784a-61b2-4f9c-ad92-3e555b33d0bf",
      "metadata": {
        "id": "e5cd784a-61b2-4f9c-ad92-3e555b33d0bf"
      },
      "outputs": [],
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "memory = MemorySaver()\n",
        "graph = graph_builder.compile(checkpointer=memory)\n",
        "\n",
        "# Specify an ID for the thread\n",
        "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f557b169-b33c-42d0-b97e-1b948d0a2914",
      "metadata": {
        "id": "f557b169-b33c-42d0-b97e-1b948d0a2914"
      },
      "source": [
        "We can now invoke similar to before:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6d16477-52f5-4755-83d1-60eebddfaaa0",
      "metadata": {
        "id": "c6d16477-52f5-4755-83d1-60eebddfaaa0",
        "outputId": "cbea0a06-96f3-417c-9293-8dec344ad20e"
      },
      "outputs": [],
      "source": [
        "input_message = \"What is Task Decomposition?\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "    config=config,\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9d6f0ee-b5a9-4141-9f6f-ad86a04e083f",
      "metadata": {
        "id": "c9d6f0ee-b5a9-4141-9f6f-ad86a04e083f",
        "outputId": "1bb7baeb-7374-4294-bac3-bb8da1b5fcfe"
      },
      "outputs": [],
      "source": [
        "input_message = \"Can you look up some common ways of doing it?\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "    config=config,\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bbbeef2-d9a1-4857-874f-9f3b5cc4eca9",
      "metadata": {
        "id": "4bbbeef2-d9a1-4857-874f-9f3b5cc4eca9"
      },
      "source": [
        "Note that the query generated by the model in the second question incorporates the conversational context.\n",
        "\n",
        "The [LangSmith](https://smith.langchain.com/public/28e6179f-fc56-45e1-9028-447d76352c14/r) trace is particularly informative here, as we can see exactly what messages are visible to our chat model at each step."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ad23c71-3c99-4d9d-b494-9b7a08a557c0",
      "metadata": {
        "id": "0ad23c71-3c99-4d9d-b494-9b7a08a557c0"
      },
      "source": [
        "## Agents {#agents}\n",
        "\n",
        "[Agents](/docs/concepts/agents) leverage the reasoning capabilities of LLMs to make decisions during execution. Using agents allows you to offload additional discretion over the retrieval process. Although their behavior is less predictable than the above \"chain\", they are able to execute multiple retrieval steps in service of a query, or iterate on a single search.\n",
        "\n",
        "Below we assemble a minimal RAG agent. Using LangGraph's [pre-built ReAct agent constructor](https://langchain-ai.github.io/langgraph/how-tos/#langgraph.prebuilt.chat_agent_executor.create_react_agent), we can do this in one line.\n",
        "\n",
        ":::tip\n",
        "\n",
        "Check out LangGraph's [Agentic RAG](https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_agentic_rag/) tutorial for more advanced formulations.\n",
        "\n",
        ":::"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "470d5996-527d-4ef1-9e31-2c259cc3c050",
      "metadata": {
        "id": "470d5996-527d-4ef1-9e31-2c259cc3c050"
      },
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "agent_executor = create_react_agent(llm, [retrieve], checkpointer=memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d8f8734-5dcf-4058-a532-11c8a7d0efae",
      "metadata": {
        "id": "7d8f8734-5dcf-4058-a532-11c8a7d0efae"
      },
      "source": [
        "Let's inspect the graph:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0907cef3-05cb-45c7-ab46-382c58c52eb1",
      "metadata": {
        "id": "0907cef3-05cb-45c7-ab46-382c58c52eb1",
        "outputId": "01030df6-a7b8-4779-9134-e5aa4bc8546b"
      },
      "outputs": [],
      "source": [
        "display(Image(agent_executor.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28623a52-7906-440f-8aaf-d6bb5ecbad98",
      "metadata": {
        "id": "28623a52-7906-440f-8aaf-d6bb5ecbad98"
      },
      "source": [
        "The key difference from our earlier implementation is that instead of a final generation step that ends the run, here the tool invocation loops back to the original LLM call. The model can then either answer the question using the retrieved context, or generate another tool call to obtain more information.\n",
        "\n",
        "Let's test this out. We construct a question that would typically require an iterative sequence of retrieval steps to answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2f48f92-bd91-4033-a01b-7bd0667e3d87",
      "metadata": {
        "id": "a2f48f92-bd91-4033-a01b-7bd0667e3d87",
        "outputId": "b2e22740-eef6-431f-dd0a-dbf7e2db622f"
      },
      "outputs": [],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"def234\"}}\n",
        "\n",
        "input_message = (\n",
        "    \"What is the standard method for Task Decomposition?\\n\\n\"\n",
        "    \"Once you get the answer, look up common extensions of that method.\"\n",
        ")\n",
        "\n",
        "for event in agent_executor.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "    config=config,\n",
        "):\n",
        "    event[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47ab58d2-92ef-4940-a535-7c8808e75523",
      "metadata": {
        "id": "47ab58d2-92ef-4940-a535-7c8808e75523"
      },
      "source": [
        "Note that the agent:\n",
        "\n",
        "1. Generates a query to search for a standard method for task decomposition;\n",
        "2. Receiving the answer, generates a second query to search for common extensions of it;\n",
        "3. Having received all necessary context, answers the question.\n",
        "\n",
        "We can see the full sequence of steps, along with latency and other metadata, in the [LangSmith trace](https://smith.langchain.com/public/48cbd35e-9ac1-49ab-8c09-500d54c06b81/r).\n",
        "\n",
        "## Next steps\n",
        "\n",
        "We've covered the steps to build a basic conversational Q&A application:\n",
        "\n",
        "- We used chains to build a predictable application that generates at most one query per user input;\n",
        "- We used agents to build an application that can iterate on a sequence of queries.\n",
        "\n",
        "To explore different types of retrievers and retrieval strategies, visit the [retrievers](/docs/how_to/#retrievers) section of the how-to guides.\n",
        "\n",
        "For a detailed walkthrough of LangChain's conversation memory abstractions, visit the [How to add message history (memory)](/docs/how_to/message_history) guide.\n",
        "\n",
        "To learn more about agents, check out the [conceptual guide](/docs/concepts/agents) and LangGraph [agent architectures](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/) page."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97b7c675-4011-43d2-9a6a-ddcf75fec536",
      "metadata": {
        "id": "97b7c675-4011-43d2-9a6a-ddcf75fec536"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
